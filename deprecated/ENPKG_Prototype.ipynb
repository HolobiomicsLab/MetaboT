{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d00cb5a",
   "metadata": {},
   "source": [
    "# ENPKG Notebook\n",
    "### Workbook used while designing and debugging KGAI. No longer up to date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e74d097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general python libs\n",
    "import json\n",
    "import os\n",
    "\n",
    "# langchain\n",
    "import langchain\n",
    "from langchain import LLMChain\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents import Tool, AgentType, initialize_agent\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains.prompt_selector import ConditionalPromptSelector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d81392e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22fe6cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import tools_script\n",
    "importlib.reload(tools_script)\n",
    "\n",
    "from tools_script import RunSparql, QueryTool, nested_value, split_data, DBRetriever, SimpleAgent, count_tokens\n",
    "import prompts\n",
    "importlib.reload(prompts)\n",
    "import prompts\n",
    "\n",
    "import enpkg_agent\n",
    "importlib.reload(enpkg_agent)\n",
    "from enpkg_agent import run_agent\n",
    "\n",
    "import enpkg_tools\n",
    "importlib.reload(enpkg_tools)\n",
    "from enpkg_tools import make_tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d48a27b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_url = 'http://Emmas-MacBook-Pro-2019.local:7200/repositories/ENPKG_local'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff793f18",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958a2749",
   "metadata": {},
   "source": [
    "## Run SPARQL Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f120cfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the endpoint URLs for the SPARQL queries\n",
    "endpoint_url = \"https://enpkg.commons-lab.org/graphdb/repositories/ENPKG\"\n",
    "\n",
    "# Set the tool name and description for the SparqlQueryRunner\n",
    "tool_name = \"SparqlQueryRunner\"\n",
    "tool_desc = \"Useful to run Sparql queries after keywords have been extracted and identifiers have been found.\"\n",
    "\n",
    "# Create an instance of the RunSparql class\n",
    "run_sparql_query = RunSparql(endpoint_url, tool_name, tool_desc)\n",
    "\n",
    "# Create the tool using the specified endpoint URL, tool name, and description\n",
    "run_sparql_query.make_tool()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5f08a2",
   "metadata": {},
   "source": [
    "## Taxon Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4bdad31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the SPARQL query template for retrieving taxon information\n",
    "taxon_template = \"\"\"\n",
    "PREFIX enpkg: <https://enpkg.commons-lab.org/kg/>\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "PREFIX enpkgmodule: <https://enpkg.commons-lab.org/module/>\n",
    "select * where {{ \n",
    "    ?extract rdf:type enpkg:LabExtract .\n",
    "    ?process enpkg:has_lab_process ?extract ; \n",
    "             enpkg:submitted_taxon '{taxon}' ;\n",
    "             enpkgmodule:has_broad_organe ?broad_organe ;\n",
    "             enpkgmodule:has_organe ?organe ;\n",
    "             enpkgmodule:has_subsystem ?subsystem ;\n",
    "             enpkgmodule:has_tissue ?tissue ;\n",
    "}} \n",
    "\"\"\"\n",
    "\n",
    "# Set the tool name and description for the TaxonLookup tool\n",
    "taxon_tool_name = 'TaxonLookup'\n",
    "taxon_tool_desc = \"\"\"Use tool when need to get extract ID for a species or taxon. \n",
    "                    Input should be taxon name.\n",
    "                    Returns dictionary of possible extract URIs for the taxon of interest with other information.\"\"\"\n",
    "\n",
    "# Define a function to format the output data from the SPARQL query\n",
    "def taxon_format(output):\n",
    "    formatted_data = {}\n",
    "    for item in output:\n",
    "        entity_id = item['extract']['value']\n",
    "        formatted_data[entity_id] = {x: item[x]['value'].split('/')[-1] for x in item if x != 'extract'}\n",
    "        formatted_data[entity_id]['Type'] = 'https://enpkg.commons-lab.org/kg/LabExtract'\n",
    "\n",
    "    if formatted_data == {}:\n",
    "        return \"No taxons were found. Either the specific taxon doesn't exist in the knowledge graph or the question is asking about all taxons. Either way tell the agent to precede.\"\n",
    "    return formatted_data\n",
    "\n",
    "# Create an instance of the QueryTool class for the TaxonLookup tool\n",
    "taxon_class = QueryTool(taxon_template, taxon_tool_desc, taxon_tool_name, taxon_format, endpoint_url)\n",
    "\n",
    "# Create the TaxonLookup tool using the specified template, name, description, formatting function, and endpoint URL\n",
    "taxon_class.make_tool()\n",
    "\n",
    "# Set the SPARQL query template for finding the best URI using available tools\n",
    "taxon_agent_template = \"\"\"\n",
    "Find the best uri for {input} using the tools available: \\\n",
    "1. TaxonLookup\n",
    "\n",
    "Return the best uri in context of this question ({question}) and say that it is an instance of the class â€“ https://enpkg.commons-lab.org/kg/LabExtract.\n",
    "\"\"\"\n",
    "#the type (https://enpkg.commons-lab.org/kg/LabExtract)\n",
    "\n",
    "# Create the TaxonTool using the specified template, list of tools (in this case only TaxonLookup), and name\n",
    "taxon_agent_desc = 'Use when you need to know the uri for a taxon. Return best extract URI in the context of the question '\n",
    "taxon_agent = SimpleAgent(taxon_agent_template.format(input=\"{input}\", question=\"{question}\"), 'TaxonTool', taxon_agent_desc, [taxon_class.tool],parser = 'keyword_question', model = 'gpt-4')\n",
    "taxon_agent.make_tool()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1801bc",
   "metadata": {},
   "source": [
    "## Chemical Class Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a23c98e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting function\n",
    "def find_noids_word(s):\n",
    "    words = s.split('_')\n",
    "    for word in words:\n",
    "        if \"noids\" in word or \"loids\" in word:\n",
    "            return word.lower()\n",
    "    return s.lower()\n",
    "\n",
    "# Define a function to parse a file containing JSON data and extract values from nested keys\n",
    "def class_parser(filepath):\n",
    "    # Open the file and load the JSON data\n",
    "    with open(filepath, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    def remove_prefix(uri, prefix='https://enpkg.commons-lab.org/kg/'):\n",
    "        return uri.split(prefix, 1)[-1]\n",
    "    \n",
    "    # Extract the values from the nested keys 'class' and 'value'\n",
    "    class_list = [remove_prefix(nested_value(x, ['class', 'value'])) for x in data['results']['bindings']]\n",
    "    class_list.sort(key=find_noids_word)\n",
    "    return class_list #'enpkg:'+\n",
    "\n",
    "# Set the template for the class tool\n",
    "class_template = \"\"\"\n",
    "Give me npc_class uris relevant to this chemical class: {question}. Return nothing if the question don't ask anything about\n",
    "any entities that could be classes. Return the uri + the prefix: 'enpkg:'\n",
    "\"\"\"\n",
    "\n",
    "# Create a PromptTemplate instance for the class tool, specifying input variables and the template\n",
    "class_prompt = PromptTemplate(\n",
    "    input_variables=['question'], #'input',\n",
    "    template=class_template\n",
    ")\n",
    "\n",
    "# Set the description and name for the class tool\n",
    "class_tool_desc = 'Use to retrieve URIs for chemical classes mentioned in the question.'\n",
    "class_tool_name = 'ClassTool'\n",
    "\n",
    "# Set the filepath of the JSON file containing the class data\n",
    "class_filepath = './local_files/npc_classes.json'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4b87893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split the documents\n",
      "You have 20 document(s) in your data\n"
     ]
    }
   ],
   "source": [
    "# get embeddings for chemical class doc\n",
    "ClassDB = split_data(class_parser(class_filepath), chunk_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "dff12f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the db_class using the provided parameters\n",
    "NPCClass = DBRetriever(class_prompt, class_filepath, class_tool_name, class_tool_desc, class_parser)\n",
    "\n",
    "# Load embeddings for the NPCClass instance using the provided ClassDB\n",
    "NPCClass.load_embeddings(ClassDB)\n",
    "\n",
    "# Make the tool ready for use by calling the make_tool() method on the NPCClass instance\n",
    "NPCClass.make_tool(docs=6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74671491",
   "metadata": {},
   "source": [
    "## Target Name Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12f55907",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_prompt_template = \"\"\"For this target: {input}, what is the most relevant target name? \n",
    "'Leishmania donovani', 'Trypanosoma cruzi', 'Trypanosoma brucei rhodesiense'\n",
    "Answer with either one of those 3 options or say there is no relevant target name\n",
    "\"\"\" \n",
    "\n",
    "target_prompt = PromptTemplate(input_variables=[\"input\"],\n",
    "                               template=target_prompt_template)\n",
    "\n",
    "target_agent_desc = 'Use to get the correct string for the target name to use in SPARQL query'\n",
    "\n",
    "target_agent = SimpleAgent(target_prompt_template, 'TargetTool', target_agent_desc, [], model='gpt-3.5-turbo')\n",
    "target_agent.make_tool()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9c8cb0",
   "metadata": {},
   "source": [
    "## Structure Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fe81aabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the SPARQL query template for subquering structures\n",
    "structure_template = \"\"\"\n",
    "PREFIX idsm: <https://idsm.elixir-czech.cz/sparql/endpoint/>\n",
    "PREFIX sachem: <http://bioinfo.uochb.cas.cz/rdf/v1.0/sachem#>\n",
    "\n",
    "?ik enpkg:has_wd_id ?wd_id .\n",
    "    SERVICE idsm:wikidata {{\n",
    "        VALUES ?SUBSTRUCTURE {{\"{input}\"}} \n",
    "        ?wd_id sachem:substructureSearch _:b16.\n",
    "        _:b16 sachem:query ?SUBSTRUCTURE.\n",
    "    }}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Create sparql template format tool\n",
    "def format_structure_template(smiles):\n",
    "    return structure_template.format(input=smiles)\n",
    "\n",
    "format_structure_tool = Tool(name = 'StructureQueryTool',\n",
    "                             description= 'Format the structure sparql template',\n",
    "                             func = format_structure_template)\n",
    "\n",
    "structure_agent_template = \"\"\"\n",
    "Instructions:\n",
    "1. Check if input is a SMILES chemical structure. If yes continue, else say that the input is not a SMILES so need to ask user for the SMILES.\n",
    "2. Run the tool StructureQueryTool with the input.\n",
    "3. Return SPARQL subquery. \n",
    "Input: {input}\n",
    "\"\"\"\n",
    "\n",
    "# Create the TaxonTool using the specified template, list of tools (in this case only TaxonLookup), and name\n",
    "structure_agent_desc = 'Use when you need to get the sparql subquery to retrieve structures.'\n",
    "structure_agent = SimpleAgent(structure_agent_template, 'StructureTool', structure_agent_desc, [format_structure_tool])\n",
    "structure_agent.make_tool()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e959c0b2",
   "metadata": {},
   "source": [
    "## Tool: Unit Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9a8f599b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to parse a file containing JSON data and extract values from nested keys\n",
    "def unit_parser(filepath):\n",
    "    # Open the file and load the JSON data\n",
    "    with open(filepath, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "# Set the template for the unit tool\n",
    "unit_template = \"\"\"\n",
    "Give me units relevant to numerical values in this question: {question}. Return nothing if units for value is not provided.\n",
    "\"\"\"\n",
    "\n",
    "# Create a PromptTemplate instance for the unit tool, specifying input variables and the template\n",
    "unit_prompt = PromptTemplate(\n",
    "    input_variables=['question'], \n",
    "    template=unit_template\n",
    ")\n",
    "\n",
    "# Set the description and name for the unit tool\n",
    "unit_tool_desc = 'Use to retrieve units if question mentions a numerical measure.'\n",
    "unit_tool_name = 'UnitTool'\n",
    "\n",
    "# Set the filepath of the JSON file containing the unit data\n",
    "unit_filepath = './local_files/ENPKG_units.json'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9f95c5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split the documents\n",
      "You have 1 document(s) in your data\n"
     ]
    }
   ],
   "source": [
    "UnitDB = split_data(unit_parser(unit_filepath), chunk_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e69c0b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the db_class using the provided parameters\n",
    "Unit = DBRetriever(unit_prompt, unit_filepath, unit_tool_name, unit_tool_desc, unit_parser)\n",
    "\n",
    "# Load embeddings for the NPCClass instance using the provided ClassDB\n",
    "Unit.load_embeddings(UnitDB)\n",
    "\n",
    "# Make the tool ready for use by calling the make_tool() method on the NPCClass instance\n",
    "Unit.make_tool(docs=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ca53db",
   "metadata": {},
   "source": [
    "## Tool: Identifier Lookup (NO LONGER USED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12e8da7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identifier_lookup(search, entity_type = \"entity\",\n",
    "                 limit = 50, \n",
    "                 info_type = ['label', 'description'] # information to include with id\n",
    "                ):    \n",
    "\n",
    "    search = f\"'{search}'\"\n",
    "    SPARQL_template = \"\"\"\n",
    "    SELECT DISTINCT ?entity ?entityLabel ?entityDescription\n",
    "    WHERE {{\n",
    "    {{\n",
    "        ?entity rdfs:label {searchstr}@en .\n",
    "        ?entity rdfs:label ?entityLabel\n",
    "        OPTIONAL {{\n",
    "          ?entity rdfs:comment ?entityDescription .\n",
    "        }}\n",
    "      }}\n",
    "    }}\n",
    "    \"\"\" \n",
    "    \n",
    "    try:\n",
    "        output = run_sparql(SPARQL_template.format(searchstr=search))\n",
    "\n",
    "\n",
    "        formatted_data = {}\n",
    "\n",
    "        for item in output:\n",
    "            entity_id = item['entity']['value'].split('/')[-1]\n",
    "            label = item['entityLabel']['value']\n",
    "            description = item.get('entityDescription', {}).get('value', '')\n",
    "            item_type = 'property' if entity_id[0] == 'P' else 'entity'\n",
    "            formatted_data[entity_id] = {'label': label, 'description': description}\n",
    "        return formatted_data\n",
    "    except:\n",
    "        return \"Sorry, I got an error. Please try again.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "76d30ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_template = \"\"\"\n",
    "Find the best uri for {input} using the tools available: \\\n",
    "1. ItemLookup\n",
    "\n",
    "Return the best uri with the label and description in context of this question: {question}\n",
    "\"\"\"\n",
    "\n",
    "property_template = \"\"\"\n",
    "Find the best p-number for {input} using the tools available: \\\n",
    "1. PropertyLookup\n",
    "\n",
    "Return the best p-number with the label and description in context of this question: {question}. \n",
    "\n",
    "Note: don't answer the question.\n",
    "\"\"\"\n",
    "\n",
    "item_tool = [Tool(\n",
    "    name = 'ItemLookup',\n",
    "    description = 'Useful when you need to know the uri for an item in order to generate a sparql request. \\\n",
    "        Provides a list of possible identifiers.',\n",
    "    func = lambda item: identifier_lookup(item, entity_type='entity')\n",
    ")]\n",
    "    \n",
    "property_tool = [Tool(\n",
    "    name = 'PropertyLookup',\n",
    "    description = 'Useful when you need to know the p-number for a property in order to generate a sparql request. \\\n",
    "        Provides a list of possible p-numbers.',\n",
    "    func = lambda item: identifier_lookup(item, entity_type='property')\n",
    ")]\n",
    "\n",
    "def make_tool(template, tools, tool_name):\n",
    "    def parsing(string):\n",
    "        split = string.split(\":\")\n",
    "        keyword, question = split[0], ':'.join(split[1:])\n",
    "        id_prompt = PromptTemplate(\n",
    "            input_variables=['input', 'question'],\n",
    "            template = template\n",
    "        )\n",
    "        llm = ChatOpenAI(temperature=0.8, model=\"gpt-4\", verbose=True)\n",
    "        llm_chain = LLMChain(prompt=id_prompt, llm=llm, verbose = True)\n",
    "        id_agent = initialize_agent(tools, llm, agent=AgentType.OPENAI_FUNCTIONS, verbose = True)\n",
    "\n",
    "        return id_agent.run(id_prompt.format(input=keyword,question=question))\n",
    "    \n",
    "    tool_desc = 'Use when you need to know the uri for a taxon. \\\n",
    "        Return best extract URI in the context of the question '\n",
    "    \n",
    "    id_tool = Tool(\n",
    "        name = tool_name,\n",
    "        description = tool_desc,\n",
    "        func = parsing\n",
    "    )\n",
    "    \n",
    "    return id_tool\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2404a85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_id_tools = make_tool(item_template, item_tool+property_tool, 'ItemTool')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "75792cf7",
   "metadata": {},
   "source": [
    "## Tool : load schema (NO LONGER USED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "538fa000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_prefix(uri, prefix='https://enpkg.commons-lab.org/'):\n",
    "    return uri.split(prefix, 1)[-1]\n",
    "\n",
    "def condense_parse(entities):\n",
    "\n",
    "    with open(entities, 'r') as e:\n",
    "        entity_dict = json.load(e)\n",
    "    parsed = {x:{y:entity_dict[x][y][0]['value'] for y in entity_dict[x]} for x in entity_dict}\n",
    "\n",
    "    with open('./chemistry_schema/enpkg_predicates_clean.json', 'r') as p:\n",
    "        pred_dict = json.load(p)\n",
    "\n",
    "    new_dict = {}\n",
    "\n",
    "    for key, value in parsed.items():\n",
    "        new_value = {}\n",
    "        try:\n",
    "            if value.get('http://www.w3.org/1999/02/22-rdf-syntax-ns#type') == 'http://www.w3.org/2000/01/rdf-schema#Class':\n",
    "                new_value['Type'] = 'Entity'\n",
    "            else:\n",
    "                new_value['Type'] = value.get('http://www.w3.org/1999/02/22-rdf-syntax-ns#type')\n",
    "            new_value['Label'] = value.get('http://www.w3.org/2000/01/rdf-schema#label')\n",
    "            new_value['Description'] = value.get('http://www.w3.org/2000/01/rdf-schema#comment')\n",
    "        except:\n",
    "            continue\n",
    "        new_dict[remove_prefix(key)] = new_value\n",
    "\n",
    "    new_dict = {x:y for x,y in new_dict.items() if y['Type']=='Entity'}\n",
    "\n",
    "    for key, value in pred_dict.items():\n",
    "        for pred in value:\n",
    "            if 'https://enpkg.commons-lab.org/' in pred:\n",
    "                new_dict[remove_prefix(pred)] = {'Type':'Predicate'}\n",
    "\n",
    "    return new_dict\n",
    "\n",
    "def condense_parse_local(entities):\n",
    "    with open(entities, 'r') as e:\n",
    "        entity_dict = json.load(e)['results']['bindings']\n",
    "    parsed = {nested_value(x, ['o','value']):{'label': nested_value(x, ['label', 'value']), 'comment': nested_value(x, ['comment', 'value'])} for x in entity_dict}\n",
    "    with open('./chemistry_schema/enpkg_local_predicates.json', 'r') as p:\n",
    "        pred_dict = json.load(p)\n",
    "\n",
    "    new_dict = {}\n",
    "\n",
    "    for key, value in parsed.items():\n",
    "        new_value = {}\n",
    "        new_value['Type'] = 'Entity'\n",
    "        try:\n",
    "            new_value['Label'] = value.get('label')\n",
    "            new_value['Description'] = value.get('comment')\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        new_dict[remove_prefix(key)] = new_value\n",
    "\n",
    "\n",
    "    new_dict = {x:y for x,y in new_dict.items() if y['Type']=='Entity'}\n",
    "\n",
    "    for key, value in pred_dict.items():\n",
    "        for pred in value:\n",
    "            if 'https://enpkg.commons-lab.org/' in pred:\n",
    "                new_dict[remove_prefix(pred)] = {'Type':'Predicate'}\n",
    "\n",
    "    return new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6d677879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split the documents\n",
      "You have 7 document(s) in your data\n"
     ]
    }
   ],
   "source": [
    "CondenseDB = split_data(condense_parse_local(schema_filepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "a92ad3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split the documents\n",
      "You have 15 document(s) in your data\n"
     ]
    }
   ],
   "source": [
    "CondenseChunkDB = split_data(condense_parse_local(schema_filepath), chunk_size=100, chunk_overlap=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "id": "ca7371d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "CondenseClass = DBRetriever(schema_prompt, schema_filepath, schema_tool_name, schema_tool_desc, condense_parse)\n",
    "CondenseClass.load_embeddings(CondenseDB)\n",
    "CondenseClass.make_tool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "8e33e19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CondenseChunkClass = DBRetriever(schema_prompt, schema_filepath, schema_tool_name, schema_tool_desc, condense_parse)\n",
    "CondenseChunkClass.load_embeddings(CondenseChunkDB)\n",
    "CondenseChunkClass.make_tool(docs = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7b2758b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def schema_parser(entities):\n",
    "    with open(entities, 'r') as e:\n",
    "        entity_dict = json.load(e)['results']['bindings']\n",
    "    #parsed = {x:{y:entity_dict[x][y][0]['value'] for y in entity_dict[x]} for x in entity_dict}\n",
    "    \n",
    "    parsed = {nested_value(x, ['o','value']):{'label': nested_value(x, ['label', 'value']), 'comment': nested_value(x, ['comment', 'value'])} for x in entity_dict}\n",
    "    with open('./chemistry_schema/enpkg_local_predicates.json', 'r') as p:\n",
    "        pred_dict = json.load(p)\n",
    "\n",
    "\n",
    "    new_dict = {}\n",
    "\n",
    "    for key, value in parsed.items():\n",
    "        new_value = {}\n",
    "        try:\n",
    "            if value.get('http://www.w3.org/1999/02/22-rdf-syntax-ns#type') == 'http://www.w3.org/2000/01/rdf-schema#Class':\n",
    "                new_value['Type'] = 'Entity'\n",
    "            else:\n",
    "                new_value['Type'] = value.get('http://www.w3.org/1999/02/22-rdf-syntax-ns#type')\n",
    "            new_value['Label'] = value.get('http://www.w3.org/2000/01/rdf-schema#label')\n",
    "            new_value['Description'] = value.get('http://www.w3.org/2000/01/rdf-schema#comment')\n",
    "        except:\n",
    "            continue\n",
    "        new_dict[remove_prefix(key)] = new_value\n",
    "\n",
    "    new_dict = {x:y for x,y in new_dict.items() if y['Type']=='Entity'}\n",
    "\n",
    "    for key, value in pred_dict.items():\n",
    "        for pred in value:\n",
    "            if 'https://enpkg.commons-lab.org/' in pred:\n",
    "                new_pred = remove_prefix(pred)\n",
    "                try:\n",
    "                    new_dict[new_pred]['Property of Classes'].append(remove_prefix(key))\n",
    "                except:\n",
    "                    new_dict[new_pred] = {'Type':'Predicate', 'Property of Classes':[remove_prefix(key)]}\n",
    "        \n",
    "        try:\n",
    "            new_dict[remove_prefix(key)]['Has predicates'] = [remove_prefix(pred) for pred in value]\n",
    "        except:\n",
    "            pass\n",
    "    return new_dict\n",
    "\n",
    "schema_template = \"\"\"\n",
    "Give me a list possible uris for entities AND predicates (not just predicates) relevant to this question: {question}. Only include if relevant.\n",
    "The format of the document is a URI followed by a dictionary of information (the type, label, description)\n",
    "\"\"\"\n",
    "\n",
    "schema_prompt = PromptTemplate(\n",
    "    input_variables=['question'], #'input', \n",
    "    template = schema_template\n",
    ")\n",
    "\n",
    "schema_tool_desc = 'Use when you need to know the relevant URIs for a question. \\\n",
    "        Example input: \"what is the age of Obama?\" '\n",
    "schema_tool_name = 'IDTool'\n",
    "schema_filepath = './chemistry_schema/enpkg_local_schema.json' #change for non-local version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "359804ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split the documents\n",
      "You have 7 document(s) in your data\n"
     ]
    }
   ],
   "source": [
    "LongDB = split_data(schema_parser(schema_filepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "5443ef3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split the documents\n",
      "You have 36 document(s) in your data\n"
     ]
    }
   ],
   "source": [
    "LongChunkDB = split_data(schema_parser(schema_filepath), chunk_size=100, chunk_overlap=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "id": "592b0395",
   "metadata": {},
   "outputs": [],
   "source": [
    "SchemaClass = DBRetriever(schema_prompt, schema_filepath, schema_tool_name, schema_tool_desc, schema_parser)\n",
    "SchemaClass.load_embeddings(LongDB)\n",
    "SchemaClass.make_tool()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "5aecebd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "SchemaChunkClass = DBRetriever(schema_prompt, schema_filepath, schema_tool_name, schema_tool_desc, schema_parser)\n",
    "SchemaChunkClass.load_embeddings(LongChunkDB)\n",
    "SchemaChunkClass.make_tool(docs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "4c5403fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def get_uris(question, Class, doc_list):\n",
    "    print(question)\n",
    "    for d in doc_list:\n",
    "        start_time = time.time()\n",
    "\n",
    "        Class.make_tool(docs=d)\n",
    "\n",
    "        print('Results for get documents number:', d)\n",
    "        print(Class.retriever.run(schema_prompt.format(question=question)))\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "        print('Execution time:', execution_time, 'seconds')\n",
    "        print('')\n",
    "\n",
    "\n",
    "def get_uris2(question, Class_list, doc_list, filename):\n",
    "    with open(filename, 'a') as f:\n",
    "        f.write(question + '\\n')\n",
    "        for Class, doc in zip(Class_list, doc_list):\n",
    "            start_time = time.time()\n",
    "\n",
    "            Class.make_tool(docs=doc)\n",
    "\n",
    "            f.write('Results for class with doc number: {}\\n'.format(doc))\n",
    "            f.write(str(Class.retriever.run(schema_prompt.format(question=question))) + '\\n')\n",
    "            end_time = time.time()\n",
    "            execution_time = end_time - start_time\n",
    "            f.write('Execution time: {} seconds\\n'.format(execution_time))\n",
    "            f.write('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca4d465",
   "metadata": {},
   "outputs": [],
   "source": [
    "for q in [q1, q2, q3, q4, q5, q6, q7, q8]:\n",
    "    get_uris(q, SchemaClass, [2,4,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "id": "1a7527d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for q in [q1, q2, q3, q4, q5, q6, q7, q8]:\n",
    "    get_uris(q, CondenseChunkClass, [2,4,7,10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e95d69",
   "metadata": {},
   "source": [
    "## Tool: Schema Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "0f7ade52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retriever_schema(arg):\n",
    "    with open('./local_files/merged.ttl', 'r') as file:\n",
    "        ttl_schema = file.read()\n",
    "    return ttl_schema\n",
    "\n",
    "SchemaRetrieverTool = Tool(name = 'SchemaRetrieverTool',\n",
    "                           description = 'Useful to get all triples of knowledge graph schema',\n",
    "                           func = retriever_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005d1bfa",
   "metadata": {},
   "source": [
    "# Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10c482f",
   "metadata": {},
   "source": [
    "## Prompt Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0fdb92f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def asks_structure(question) -> bool:\n",
    "    return 'structure' in question.lower() \n",
    "\n",
    "prompt_selector = ConditionalPromptSelector(\n",
    "    default_prompt=prompts.default_prompt2, conditionals=[(lambda x: False, prompts.structure_prompt)]\n",
    ")\n",
    "\n",
    "def return_prompt(question, schema=ttl_schema):\n",
    "    return prompt_selector.get_prompt(question).format(question = question) #, schema=schema\n",
    "\n",
    "def run_agent_simple(question, schema=ttl_schema):\n",
    "    prompts_dict = {'default':prompts.default_prompt2, 'structure':prompts.structure_prompt}\n",
    "    if asks_structure(question):\n",
    "        prompt = prompts_dict['structure']\n",
    "        tools = [run_sparql_query.tool, taxon_agent.tool, target_agent.tool, structure_agent.tool, NPCClass.tool, SchemaRetrieverTool, Unit.tool]\n",
    "    else:\n",
    "        prompt = prompts_dict['default']\n",
    "        tools = [run_sparql_query.tool, taxon_agent.tool, target_agent.tool, NPCClass.tool, SchemaRetrieverTool, Unit.tool]\n",
    "    llm = ChatOpenAI(temperature=0.3, model=\"gpt-4\", verbose=True)\n",
    "    agent = initialize_agent(tools, llm, prompt = prompt_selector, agent=AgentType.OPENAI_FUNCTIONS, verbose = True)\n",
    "    agent.run(prompt.format(question=question))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7e12a0",
   "metadata": {},
   "source": [
    "## Prompt with ttl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de5a85c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_map = {'http://schema.org/':'schema:',\n",
    "              'https://enpkg.commons-lab.org/module/':'em:',\n",
    "              'http://purl.org/pav/':'pav:',\n",
    "              'http://example.org/':'example:',\n",
    "              'https://enpkg.commons-lab.org/kg/':'e:',\n",
    "              'http://purl.org/dc/terms/':'dcterms:',\n",
    "              'http://xmlns.com/foaf/0.1/': 'foaf:',\n",
    "              'http://proton.semanticweb.org/protonsys#':'proton:',\n",
    "              'http://www.w3.org/2001/XMLSchema#': 'xsd:',\n",
    "              'http://www.w3.org/2000/01/rdf-schema#':'rdfs:',\n",
    "              'http://www.w3.org/1999/02/22-rdf-syntax-ns#': 'rdf:',\n",
    "              'http://www.w3.org/2002/07/owl#': 'owl:',\n",
    "              'http://purl.org/vocab/vann/': 'vann:'}\n",
    "\n",
    "def get_prefix(url):\n",
    "    for prefix, substitution in prefix_map.items():\n",
    "        if url.startswith(prefix):\n",
    "            substituted_url = url.replace(prefix, substitution)\n",
    "            return substituted_url\n",
    "    return url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a25c4643",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph\n",
    "\n",
    "\n",
    "# load schema\n",
    "with open('schema_local_ttl/merged.ttl', 'r') as file:\n",
    "    ttl_schema = file.read()\n",
    "\n",
    "# Create an empty RDF graph\n",
    "graph = Graph()\n",
    "\n",
    "# Parse the TTL schema string\n",
    "graph.parse(data=ttl_schema, format='turtle')\n",
    "\n",
    "# Retrieve the explicit triples as a list\n",
    "triples = [(get_prefix(str(s)), get_prefix(str(p)), get_prefix(str(o))) for s, p, o in graph if get_prefix(str(o)) != '']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e62f43a",
   "metadata": {},
   "source": [
    "#### 1 Agent generate sparql\n",
    "\n",
    "Prompt: simple_agent_prompt\n",
    "\n",
    "Input: schema, question\n",
    "\n",
    "Tools: simple_agent_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e05deaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_agent_prompt = \"\"\"\n",
    "You are trying to generate a SPARQL query for the Experiment Natural Products Knowledge Graph (ENPKG) based on a natural language question. Here are your instructions:\n",
    "\n",
    "1. Generate sparql query\n",
    "2. Run sparql query with SparqlQueryRunner Tool\n",
    "\n",
    "\n",
    "Note:\n",
    "* DO NOT assume any identifiers \n",
    "* This is NOT the wikidata knowledge graph\n",
    "\n",
    "Use the schema below for identifying relavent URIs and to understand instances of what classes or related to others. Here is the schema of ENPKG is .ttl format. The entities listed indicate the type of objects that the predicates relate.\n",
    "{schema}\n",
    "\n",
    "You can use this prefix (replace the start of the URI with the prefix):\n",
    "PREFIX enpkg: <https://enpkg.commons-lab.org/kg/>\n",
    "PREFIX enpkg_module: <https://enpkg.commons-lab.org/module/>\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "simple_agent_tools = [run_sparql_query.tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b13d4c",
   "metadata": {},
   "source": [
    "#### 1 Agent with Taxon and Chemical Class Tools\n",
    "\n",
    "Prompt: option2_prompt\n",
    "\n",
    "Input: schema, question\n",
    "\n",
    "Tools: option2_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dd6221a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "option2_tools = [run_sparql_query.tool, taxon_agent.tool, target_agent.tool, structure_agent.tool, NPCClass.tool, SchemaRetrieverTool]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037515bd",
   "metadata": {},
   "source": [
    "#### Nested Agents with only generate sparql\n",
    "\n",
    "Prompt: outer_prompt\n",
    "\n",
    "Input: question\n",
    "\n",
    "Tools: nested_agent_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3278b094",
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_prompt = \"\"\"\n",
    "You are trying to generate a SPARQL query for the Experiment Natural Products Knowledge Graph (ENPKG) based on a natural language question. Here are your instructions:\n",
    "\n",
    "Return generate SPARQL query with nothing else.\n",
    "\n",
    "\n",
    "Note:\n",
    "* DO NOT assume any identifiers \n",
    "* This is NOT the wikidata knowledge graph\n",
    "\n",
    "Use the schema below for identifying relavent URIs and to understand instances of what classes or related to others. Here is the schema of ENPKG is .ttl format. The entities listed indicate the type of objects that the predicates relate.\n",
    "{schema}\n",
    "\n",
    "You can use this prefix (replace the start of the URI with the prefix):\n",
    "PREFIX enpkg: <https://enpkg.commons-lab.org/kg/>\n",
    "PREFIX enpkg_module: <https://enpkg.commons-lab.org/module/>\n",
    "\n",
    "Question: {question}\"\"\"\n",
    "nested_prompt = nested_prompt.format(schema=ttl_schema, question=\"{question}\")\n",
    "nested_prompt_template = PromptTemplate(\n",
    "    template=nested_prompt,\n",
    "    input_variables=[\"question\"]\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-4\")\n",
    "llm_chain = LLMChain(prompt=nested_prompt_template, llm=llm)\n",
    "generate_sparql = Tool(name = 'GenerateSPARQL',\n",
    "                       description = 'Generate a sparql query given a question',\n",
    "                       func=llm_chain)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca8c297b",
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_prompt = \"\"\"Use the following two tools to generate a sparql query and run the query for the inputted question.\n",
    "Tools:\n",
    "\n",
    "1. GenerateSPARQL\n",
    "2. SparqlQueryRunner\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "nested_agent_tools = [run_sparql_query.tool, generate_sparql]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d93517b",
   "metadata": {},
   "source": [
    "#### Nested Agent with Taxon and Chemical tools outside generate sparql tool\n",
    "\n",
    "Prompt: option3_outer_prompt\n",
    "\n",
    "Input: question\n",
    "\n",
    "Tools: option3_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "85d18e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "option3_outer_prompt = \"\"\"\n",
    "You are trying to answer a question using the Experiment Natural Products Knowledge Graph (ENPKG). Here are your instructions:\n",
    "\n",
    "1. ONLY IF a taxon is mentioned, use TaxonTool\n",
    "2. ONLY IF a chemical class is mentioned used ClassTool\n",
    "3. Use GenerateSPARQL tool after use of first two tools\n",
    "4. Run sparql query with SparqlQueryRunner Tool\n",
    "\n",
    "Question: {question}\"\"\"\n",
    "\n",
    "option3_inner_prompt = \"\"\"\n",
    "Use the schema below for identifying relavent URIs and to understand instances of what classes or related to others. Here is the schema of ENPKG is .ttl format. The entities listed indicate the type of objects that the predicates relate.\n",
    "{schema}\n",
    "\n",
    "Use chat memory for taxon and chemical class information:\n",
    "{chat_history} \n",
    "\n",
    "You can use this prefix (replace the start of the URI with the prefix):\n",
    "PREFIX enpkg: <https://enpkg.commons-lab.org/kg/>\n",
    "PREFIX enpkg_module: <https://enpkg.commons-lab.org/module/>\n",
    "\n",
    "Question: {question}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "04cac836",
   "metadata": {},
   "outputs": [],
   "source": [
    "option3_prompt = option3_inner_prompt.format(schema=ttl_schema, question=\"{question}\", chat_history=\"{chat_history}\")\n",
    "option3_prompt_template = PromptTemplate(\n",
    "    template=option3_prompt,\n",
    "    input_variables=[\"question\", \"chat_history\"]\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-4\")\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "llm_chain = LLMChain(prompt=option3_prompt_template, llm=llm, memory=memory)\n",
    "generate_sparql_memory = Tool(name = 'GenerateSPARQL',\n",
    "                       description = 'Generate a sparql query given a question',\n",
    "                       func=lambda x: llm_chain.predict(question=x))\n",
    "\n",
    "option3_tools = [run_sparql_query.tool, generate_sparql_memory, taxon_class.tool, NPCClass.tool]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08580726",
   "metadata": {},
   "source": [
    "### Create final agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "9dfc428d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tools = [generate_sparql, run_sparql_query.tool] #+ [taxon_agent] + [NPCClass.tool]\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "prompt = PromptTemplate(\n",
    "    template=prompts.option2_prompt_template,\n",
    "    input_variables=[\"question\", \"schema\"]\n",
    ")\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-4\", verbose=True)\n",
    "agent = initialize_agent(option2_tools, llm, prompt = prompt_selector, agent=AgentType.OPENAI_FUNCTIONS, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "da29d3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many features (pos ionization and neg ionization modes) have the same SIRIUS/CSI:FingerID and ISDB annotation by comparing the InCHIKey of the annotations?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `SchemaRetrieverTool` with `How many features (pos ionization and neg ionization modes) have the same SIRIUS/CSI:FingerID and ISDB annotation by comparing the InCHIKey of the annotations?`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m@prefix dcterms: <http://purl.org/dc/terms/> .\n",
      "@prefix enpkg: <https://enpkg.commons-lab.org/kg/> .\n",
      "@prefix enpkg_module: <https://enpkg.commons-lab.org/module/> .\n",
      "@prefix foaf: <http://xmlns.com/foaf/0.1/> .\n",
      "@prefix ns1: <http://proton.semanticweb.org/protonsys#> .\n",
      "@prefix owl: <http://www.w3.org/2002/07/owl#> .\n",
      "@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .\n",
      "@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n",
      "@prefix vann: <http://purl.org/vocab/vann/> .\n",
      "@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\n",
      "\n",
      "owl:Ontology dcterms:contributor \"\" ;\n",
      "    dcterms:creator \"\" ;\n",
      "    dcterms:description xsd:string ;\n",
      "    dcterms:license \"\" ;\n",
      "    dcterms:title xsd:string ;\n",
      "    vann:preferredNamespacePrefix xsd:string ;\n",
      "    vann:preferredNamespaceUri xsd:string ;\n",
      "    owl:versionIRI \"\" ;\n",
      "    owl:versionInfo xsd:string ;\n",
      "    foaf:logo \"\" .\n",
      "\n",
      "enpkg:CSpair enpkg:has_cosine xsd:float ;\n",
      "    enpkg:has_mass_difference xsd:float ;\n",
      "    enpkg:has_member enpkg:GNPSConsensusSpectrum,\n",
      "        enpkg:MS2Spectrum .\n",
      "\n",
      "enpkg:LFpair enpkg:has_cosine xsd:float ;\n",
      "    enpkg:has_mass_difference xsd:float ;\n",
      "    enpkg:has_member enpkg:LCMSFeature,\n",
      "        enpkg:MS2Spectrum ;\n",
      "    enpkg:has_member_1 enpkg:LCMSFeature,\n",
      "        enpkg:MS2Spectrum ;\n",
      "    enpkg:has_member_2 enpkg:LCMSFeature,\n",
      "        enpkg:MS2Spectrum .\n",
      "\n",
      "enpkg:LabBlank rdfs:label xsd:string ;\n",
      "    enpkg:has_LCMS enpkg:LCMSAnalysis,\n",
      "        enpkg:LCMSAnalysisNeg,\n",
      "        enpkg:LCMSAnalysisPos .\n",
      "\n",
      "enpkg:LabQc rdfs:label xsd:string ;\n",
      "    enpkg:has_LCMS enpkg:LCMSAnalysis,\n",
      "        enpkg:LCMSAnalysisNeg,\n",
      "        enpkg:LCMSAnalysisPos .\n",
      "\n",
      "enpkg:RawMaterial enpkg:has_lab_process enpkg:LabExtract,\n",
      "        enpkg:LabObject ;\n",
      "    enpkg:has_unresolved_taxon \"\" ;\n",
      "    enpkg:has_wd_id enpkg:WDTaxon,\n",
      "        enpkg:XRef ;\n",
      "    enpkg:submitted_taxon xsd:string ;\n",
      "    enpkg_module:has_broad_organe \"\" ;\n",
      "    enpkg_module:has_organe \"\" ;\n",
      "    enpkg_module:has_subsystem \"\" ;\n",
      "    enpkg_module:has_tissue \"\" .\n",
      "\n",
      "enpkg:SpectralPair enpkg:has_cosine xsd:float ;\n",
      "    enpkg:has_mass_difference xsd:float ;\n",
      "    enpkg:has_member enpkg:GNPSConsensusSpectrum,\n",
      "        enpkg:LCMSFeature,\n",
      "        enpkg:MS2Spectrum ;\n",
      "    enpkg:has_member_1 enpkg:LCMSFeature,\n",
      "        enpkg:MS2Spectrum ;\n",
      "    enpkg:has_member_2 enpkg:LCMSFeature,\n",
      "        enpkg:MS2Spectrum .\n",
      "\n",
      "enpkg:InChIkey enpkg:has_npc_class enpkg:ChemicalEntity,\n",
      "        enpkg:NPCClass,\n",
      "        enpkg:NPCPathway,\n",
      "        enpkg:NPCSuperclass ;\n",
      "    enpkg:has_npc_pathway enpkg:ChemicalEntity,\n",
      "        enpkg:NPCClass,\n",
      "        enpkg:NPCPathway,\n",
      "        enpkg:NPCSuperclass ;\n",
      "    enpkg:has_npc_superclass enpkg:ChemicalEntity,\n",
      "        enpkg:NPCClass,\n",
      "        enpkg:NPCPathway,\n",
      "        enpkg:NPCSuperclass ;\n",
      "    enpkg:has_smiles xsd:string ;\n",
      "    enpkg:has_wd_id enpkg:WDChemical,\n",
      "        enpkg:XRef ;\n",
      "    enpkg_module:has_chembl_id enpkg:XRef,\n",
      "        enpkg_module:ChEMBLChemical .\n",
      "\n",
      "rdfs:Datatype rdfs:subClassOf rdfs:Class,\n",
      "        rdfs:Datatype,\n",
      "        \"\" .\n",
      "\n",
      "enpkg:BioAssayResults rdfs:label xsd:string ;\n",
      "    enpkg_module:inhibition_percentage xsd:float ;\n",
      "    enpkg_module:target_id enpkg:XRef,\n",
      "        enpkg_module:ChEMBLTarget .\n",
      "\n",
      "enpkg:GNPSAnnotation enpkg:gnps_dashboard_view xsd:string ;\n",
      "    enpkg:has_InChIkey2D enpkg:InChIkey2D,\n",
      "        \"\" ;\n",
      "    enpkg:has_usi xsd:string .\n",
      "\n",
      "enpkg:IsdbAnnotation rdfs:label xsd:string ;\n",
      "    enpkg:has_InChIkey2D enpkg:InChIkey2D ;\n",
      "    enpkg:has_adduct xsd:string ;\n",
      "    enpkg:has_consistency_score xsd:float ;\n",
      "    enpkg:has_final_score xsd:float ;\n",
      "    enpkg:has_spectral_score xsd:float ;\n",
      "    enpkg:has_taxo_score xsd:float .\n",
      "\n",
      "enpkg:LabExtract rdfs:label xsd:string ;\n",
      "    enpkg:has_LCMS enpkg:LCMSAnalysis,\n",
      "        enpkg:LCMSAnalysisNeg,\n",
      "        enpkg:LCMSAnalysisPos ;\n",
      "    enpkg_module:has_bioassay_results enpkg:BioAssayResults,\n",
      "        enpkg_module:L610ugml,\n",
      "        enpkg_module:Ldono10ugml,\n",
      "        enpkg_module:Ldono2ugml,\n",
      "        enpkg_module:SwissTPHBioAssay,\n",
      "        enpkg_module:Tbrucei10ugml,\n",
      "        enpkg_module:Tbrucei2ugml,\n",
      "        enpkg_module:Tcruzi10ugml .\n",
      "\n",
      "enpkg:LabObject rdfs:label xsd:string ;\n",
      "    enpkg:has_LCMS enpkg:LCMSAnalysis,\n",
      "        enpkg:LCMSAnalysisNeg,\n",
      "        enpkg:LCMSAnalysisPos ;\n",
      "    enpkg:has_lab_process enpkg:LabExtract,\n",
      "        enpkg:LabObject ;\n",
      "    enpkg:has_unresolved_taxon \"\" ;\n",
      "    enpkg:has_wd_id enpkg:WDTaxon,\n",
      "        enpkg:XRef ;\n",
      "    enpkg:submitted_taxon xsd:string ;\n",
      "    enpkg_module:has_bioassay_results enpkg:BioAssayResults,\n",
      "        enpkg_module:L610ugml,\n",
      "        enpkg_module:Ldono10ugml,\n",
      "        enpkg_module:Ldono2ugml,\n",
      "        enpkg_module:SwissTPHBioAssay,\n",
      "        enpkg_module:Tbrucei10ugml,\n",
      "        enpkg_module:Tbrucei2ugml,\n",
      "        enpkg_module:Tcruzi10ugml ;\n",
      "    enpkg_module:has_broad_organe \"\" ;\n",
      "    enpkg_module:has_organe \"\" ;\n",
      "    enpkg_module:has_subsystem \"\" ;\n",
      "    enpkg_module:has_tissue \"\" .\n",
      "\n",
      "enpkg:SiriusCanopusAnnotation rdfs:label xsd:string ;\n",
      "    enpkg:has_canopus_npc_class enpkg:ChemicalEntity,\n",
      "        enpkg:NPCClass,\n",
      "        enpkg:NPCSuperclass,\n",
      "        \"\" ;\n",
      "    enpkg:has_canopus_npc_class_prob xsd:float ;\n",
      "    enpkg:has_canopus_npc_pathway enpkg:ChemicalEntity,\n",
      "        enpkg:NPCPathway,\n",
      "        \"\" ;\n",
      "    enpkg:has_canopus_npc_pathway_prob xsd:float ;\n",
      "    enpkg:has_canopus_npc_superclass enpkg:ChemicalEntity,\n",
      "        enpkg:NPCClass,\n",
      "        enpkg:NPCSuperclass,\n",
      "        \"\" ;\n",
      "    enpkg:has_canopus_npc_superclass_prob xsd:float .\n",
      "\n",
      "enpkg:SiriusStructureAnnotation rdfs:label xsd:string ;\n",
      "    enpkg:has_InChIkey2D enpkg:InChIkey2D ;\n",
      "    enpkg:has_cosmic_score xsd:float ;\n",
      "    enpkg:has_ionization xsd:string ;\n",
      "    enpkg:has_sirius_adduct xsd:string ;\n",
      "    enpkg:has_sirius_score xsd:float ;\n",
      "    enpkg:has_zodiac_score xsd:float .\n",
      "\n",
      "enpkg_module:ChEMBLAssayResults rdfs:label xsd:string ;\n",
      "    enpkg_module:activity_relation xsd:double,\n",
      "        xsd:string ;\n",
      "    enpkg_module:activity_type xsd:string ;\n",
      "    enpkg_module:activity_unit xsd:double,\n",
      "        xsd:string ;\n",
      "    enpkg_module:activity_value xsd:float ;\n",
      "    enpkg_module:assay_id enpkg:XRef,\n",
      "        enpkg_module:ChEMBLAssay ;\n",
      "    enpkg_module:stated_in_document enpkg:XRef,\n",
      "        enpkg_module:ChEMBLDocument ;\n",
      "    enpkg_module:target_id enpkg:XRef,\n",
      "        enpkg_module:ChEMBLTarget ;\n",
      "    enpkg_module:target_name xsd:string .\n",
      "\n",
      "enpkg_module:ChEMBLChemical enpkg_module:has_chembl_activity enpkg:XRef,\n",
      "        enpkg_module:ChEMBLAssayResults .\n",
      "\n",
      "enpkg_module:ChEMBLDocument enpkg_module:journal_name xsd:string .\n",
      "\n",
      "enpkg_module:L610ugml rdfs:label xsd:string ;\n",
      "    enpkg_module:inhibition_percentage xsd:float .\n",
      "\n",
      "enpkg_module:Ldono10ugml rdfs:label xsd:string ;\n",
      "    enpkg_module:inhibition_percentage xsd:float ;\n",
      "    enpkg_module:target_id enpkg:XRef,\n",
      "        enpkg_module:ChEMBLTarget .\n",
      "\n",
      "enpkg_module:Ldono2ugml rdfs:label xsd:string ;\n",
      "    enpkg_module:inhibition_percentage xsd:float ;\n",
      "    enpkg_module:target_id enpkg:XRef,\n",
      "        enpkg_module:ChEMBLTarget .\n",
      "\n",
      "enpkg_module:SwissTPHBioAssay rdfs:label xsd:string ;\n",
      "    enpkg_module:inhibition_percentage xsd:float ;\n",
      "    enpkg_module:target_id enpkg:XRef,\n",
      "        enpkg_module:ChEMBLTarget .\n",
      "\n",
      "enpkg_module:Tbrucei10ugml rdfs:label xsd:string ;\n",
      "    enpkg_module:inhibition_percentage xsd:float ;\n",
      "    enpkg_module:target_id enpkg:XRef,\n",
      "        enpkg_module:ChEMBLTarget .\n",
      "\n",
      "enpkg_module:Tbrucei2ugml rdfs:label xsd:string ;\n",
      "    enpkg_module:inhibition_percentage xsd:float ;\n",
      "    enpkg_module:target_id enpkg:XRef,\n",
      "        enpkg_module:ChEMBLTarget .\n",
      "\n",
      "enpkg_module:Tcruzi10ugml rdfs:label xsd:string ;\n",
      "    enpkg_module:inhibition_percentage xsd:float ;\n",
      "    enpkg_module:target_id enpkg:XRef,\n",
      "        enpkg_module:ChEMBLTarget .\n",
      "\n",
      "enpkg:LCMSFeatureList rdfs:comment xsd:string ;\n",
      "    enpkg:has_ionization xsd:string ;\n",
      "    enpkg:has_lcms_feature enpkg:LCMSFeature,\n",
      "        enpkg:MS2Spectrum .\n",
      "\n",
      "enpkg:GNPSConsensusSpectrum enpkg:gnps_component_link xsd:string ;\n",
      "    enpkg:gnps_dashboard_view xsd:string ;\n",
      "    enpkg:gnps_spectrum_link xsd:string ;\n",
      "    enpkg:has_gnps_annotation enpkg:Annotation,\n",
      "        enpkg:GNPSAnnotation ;\n",
      "    enpkg:has_metamn_ci \"\" ;\n",
      "    enpkg:has_usi xsd:string .\n",
      "\n",
      "enpkg:InChIkey2D enpkg:has_npc_class enpkg:ChemicalEntity,\n",
      "        enpkg:NPCClass,\n",
      "        enpkg:NPCPathway,\n",
      "        enpkg:NPCSuperclass ;\n",
      "    enpkg:has_npc_pathway enpkg:ChemicalEntity,\n",
      "        enpkg:NPCClass,\n",
      "        enpkg:NPCPathway,\n",
      "        enpkg:NPCSuperclass ;\n",
      "    enpkg:has_npc_superclass enpkg:ChemicalEntity,\n",
      "        enpkg:NPCClass,\n",
      "        enpkg:NPCPathway,\n",
      "        enpkg:NPCSuperclass ;\n",
      "    enpkg:has_smiles xsd:string ;\n",
      "    enpkg:is_InChIkey2D_of enpkg:ChemicalEntity,\n",
      "        enpkg:InChIkey .\n",
      "\n",
      "enpkg:LCMSAnalysis foaf:depiction \"\" ;\n",
      "    enpkg:has_gnpslcms_link \"\" ;\n",
      "    enpkg:has_lcms_feature_list enpkg:LCMSFeatureList ;\n",
      "    enpkg:has_massive_doi \"\" ;\n",
      "    enpkg:has_massive_license \"\" .\n",
      "\n",
      "enpkg:LCMSAnalysisNeg foaf:depiction \"\" ;\n",
      "    enpkg:has_gnpslcms_link \"\" ;\n",
      "    enpkg:has_lcms_feature_list enpkg:LCMSFeatureList ;\n",
      "    enpkg:has_massive_doi \"\" ;\n",
      "    enpkg:has_massive_license \"\" .\n",
      "\n",
      "enpkg:LCMSAnalysisPos foaf:depiction \"\" ;\n",
      "    enpkg:has_gnpslcms_link \"\" ;\n",
      "    enpkg:has_lcms_feature_list enpkg:LCMSFeatureList ;\n",
      "    enpkg:has_massive_doi \"\" ;\n",
      "    enpkg:has_massive_license \"\" .\n",
      "\n",
      "rdfs:Class rdfs:label xsd:string ;\n",
      "    rdfs:comment xsd:string ;\n",
      "    rdfs:subClassOf rdf:Property,\n",
      "        rdfs:Class,\n",
      "        rdfs:Datatype,\n",
      "        \"\" .\n",
      "\n",
      "owl:SymmetricProperty ns1:transitiveOver owl:SymmetricProperty,\n",
      "        owl:TransitiveProperty ;\n",
      "    rdfs:subPropertyOf rdf:Property,\n",
      "        owl:SymmetricProperty,\n",
      "        owl:TransitiveProperty ;\n",
      "    owl:inverseOf rdf:Property,\n",
      "        owl:SymmetricProperty,\n",
      "        owl:TransitiveProperty .\n",
      "\n",
      "enpkg:LCMSFeature rdfs:label xsd:string ;\n",
      "    foaf:depiction \"\" ;\n",
      "    enpkg:gnps_dashboard_view \"\" ;\n",
      "    enpkg:has_canopus_annotation enpkg:Annotation,\n",
      "        enpkg:SiriusCanopusAnnotation ;\n",
      "    enpkg:has_consensus_spectrum enpkg:GNPSConsensusSpectrum,\n",
      "        enpkg:MS2Spectrum ;\n",
      "    enpkg:has_fbmn_ci \"\" ;\n",
      "    enpkg:has_feature_area xsd:float ;\n",
      "    enpkg:has_ionization xsd:string ;\n",
      "    enpkg:has_isdb_annotation enpkg:Annotation,\n",
      "        enpkg:IsdbAnnotation ;\n",
      "    enpkg:has_parent_mass xsd:float ;\n",
      "    enpkg:has_relative_feature_area xsd:float ;\n",
      "    enpkg:has_retention_time xsd:float ;\n",
      "    enpkg:has_row_id xsd:decimal ;\n",
      "    enpkg:has_sirius_annotation enpkg:Annotation,\n",
      "        enpkg:SiriusStructureAnnotation ;\n",
      "    enpkg:has_usi xsd:string .\n",
      "\n",
      "owl:TransitiveProperty ns1:transitiveOver rdf:Property,\n",
      "        owl:SymmetricProperty,\n",
      "        owl:TransitiveProperty ;\n",
      "    rdfs:domain \"\" ;\n",
      "    rdfs:range \"\" ;\n",
      "    rdfs:subPropertyOf rdf:Property,\n",
      "        owl:TransitiveProperty ;\n",
      "    owl:inverseOf owl:SymmetricProperty,\n",
      "        owl:TransitiveProperty .\n",
      "\n",
      "enpkg:Annotation rdfs:label xsd:string ;\n",
      "    enpkg:gnps_dashboard_view xsd:string ;\n",
      "    enpkg:has_InChIkey2D enpkg:InChIkey2D,\n",
      "        \"\" ;\n",
      "    enpkg:has_adduct xsd:string ;\n",
      "    enpkg:has_canopus_npc_class enpkg:ChemicalEntity,\n",
      "        enpkg:NPCClass,\n",
      "        enpkg:NPCSuperclass,\n",
      "        \"\" ;\n",
      "    enpkg:has_canopus_npc_class_prob xsd:float ;\n",
      "    enpkg:has_canopus_npc_pathway enpkg:ChemicalEntity,\n",
      "        enpkg:NPCPathway,\n",
      "        \"\" ;\n",
      "    enpkg:has_canopus_npc_pathway_prob xsd:float ;\n",
      "    enpkg:has_canopus_npc_superclass enpkg:ChemicalEntity,\n",
      "        enpkg:NPCClass,\n",
      "        enpkg:NPCSuperclass,\n",
      "        \"\" ;\n",
      "    enpkg:has_canopus_npc_superclass_prob xsd:float ;\n",
      "    enpkg:has_consistency_score xsd:float ;\n",
      "    enpkg:has_cosmic_score xsd:float ;\n",
      "    enpkg:has_final_score xsd:float ;\n",
      "    enpkg:has_ionization xsd:string ;\n",
      "    enpkg:has_sirius_adduct xsd:string ;\n",
      "    enpkg:has_sirius_score xsd:float ;\n",
      "    enpkg:has_spectral_score xsd:float ;\n",
      "    enpkg:has_taxo_score xsd:float ;\n",
      "    enpkg:has_usi xsd:string ;\n",
      "    enpkg:has_zodiac_score xsd:float .\n",
      "\n",
      "rdf:Property rdfs:label xsd:string ;\n",
      "    ns1:transitiveOver rdf:Property,\n",
      "        owl:TransitiveProperty ;\n",
      "    rdfs:comment xsd:string ;\n",
      "    rdfs:domain rdfs:Class,\n",
      "        \"\" ;\n",
      "    rdfs:range rdfs:Class,\n",
      "        \"\" ;\n",
      "    rdfs:subClassOf rdf:Property,\n",
      "        rdfs:Class ;\n",
      "    rdfs:subPropertyOf rdf:Property,\n",
      "        owl:SymmetricProperty,\n",
      "        owl:TransitiveProperty ;\n",
      "    owl:inverseOf rdf:Property,\n",
      "        owl:SymmetricProperty .\n",
      "\n",
      "enpkg_module:ChEMBLTarget enpkg_module:target_name xsd:string .\n",
      "\n",
      "enpkg:MS2Spectrum rdfs:label xsd:string ;\n",
      "    foaf:depiction \"\" ;\n",
      "    enpkg:gnps_component_link xsd:string ;\n",
      "    enpkg:gnps_dashboard_view xsd:string,\n",
      "        \"\" ;\n",
      "    enpkg:gnps_spectrum_link xsd:string ;\n",
      "    enpkg:has_canopus_annotation enpkg:Annotation,\n",
      "        enpkg:SiriusCanopusAnnotation ;\n",
      "    enpkg:has_consensus_spectrum enpkg:GNPSConsensusSpectrum,\n",
      "        enpkg:MS2Spectrum ;\n",
      "    enpkg:has_fbmn_ci \"\" ;\n",
      "    enpkg:has_feature_area xsd:float ;\n",
      "    enpkg:has_gnps_annotation enpkg:Annotation,\n",
      "        enpkg:GNPSAnnotation ;\n",
      "    enpkg:has_ionization xsd:string ;\n",
      "    enpkg:has_isdb_annotation enpkg:Annotation,\n",
      "        enpkg:IsdbAnnotation ;\n",
      "    enpkg:has_metamn_ci \"\" ;\n",
      "    enpkg:has_parent_mass xsd:float ;\n",
      "    enpkg:has_relative_feature_area xsd:float ;\n",
      "    enpkg:has_retention_time xsd:float ;\n",
      "    enpkg:has_row_id xsd:decimal ;\n",
      "    enpkg:has_sirius_annotation enpkg:Annotation,\n",
      "        enpkg:SiriusStructureAnnotation ;\n",
      "    enpkg:has_usi xsd:string .\n",
      "\n",
      "enpkg:ChemicalEntity enpkg:has_npc_class enpkg:ChemicalEntity,\n",
      "        enpkg:NPCClass,\n",
      "        enpkg:NPCPathway,\n",
      "        enpkg:NPCSuperclass ;\n",
      "    enpkg:has_npc_pathway enpkg:ChemicalEntity,\n",
      "        enpkg:NPCClass,\n",
      "        enpkg:NPCPathway,\n",
      "        enpkg:NPCSuperclass ;\n",
      "    enpkg:has_npc_superclass enpkg:ChemicalEntity,\n",
      "        enpkg:NPCClass,\n",
      "        enpkg:NPCPathway,\n",
      "        enpkg:NPCSuperclass ;\n",
      "    enpkg:has_smiles xsd:string ;\n",
      "    enpkg:has_wd_id enpkg:WDChemical,\n",
      "        enpkg:XRef ;\n",
      "    enpkg_module:has_chembl_id enpkg:XRef,\n",
      "        enpkg_module:ChEMBLChemical .\n",
      "\n",
      "enpkg:XRef rdfs:label xsd:string ;\n",
      "    enpkg_module:activity_relation xsd:double,\n",
      "        xsd:string ;\n",
      "    enpkg_module:activity_type xsd:string ;\n",
      "    enpkg_module:activity_unit xsd:double,\n",
      "        xsd:string ;\n",
      "    enpkg_module:activity_value xsd:float ;\n",
      "    enpkg_module:assay_id enpkg:XRef,\n",
      "        enpkg_module:ChEMBLAssay ;\n",
      "    enpkg_module:has_chembl_activity enpkg:XRef,\n",
      "        enpkg_module:ChEMBLAssayResults ;\n",
      "    enpkg_module:journal_name xsd:string ;\n",
      "    enpkg_module:stated_in_document enpkg:XRef,\n",
      "        enpkg_module:ChEMBLDocument ;\n",
      "    enpkg_module:target_id enpkg:XRef,\n",
      "        enpkg_module:ChEMBLTarget ;\n",
      "    enpkg_module:target_name xsd:string .\n",
      "\n",
      "\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `SparqlQueryRunner` with `PREFIX enpkg: <https://enpkg.commons-lab.org/kg/> SELECT (COUNT(?feature) AS ?count) WHERE { ?feature a enpkg:LCMSFeature ; enpkg:has_sirius_annotation ?siriusAnnotation ; enpkg:has_isdb_annotation ?isdbAnnotation . ?siriusAnnotation enpkg:has_InChIkey2D ?inchiKey . ?isdbAnnotation enpkg:has_InChIkey2D ?inchiKey . }`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[{'count': '38964'}]\u001b[0m\u001b[32;1m\u001b[1;3mThere are 38,964 features (both positive and negative ionization modes) that have the same SIRIUS/CSI:FingerID and ISDB annotation when comparing the InCHIKey of the annotations.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Tokens Used: 10833\n",
      "\tPrompt Tokens: 10608\n",
      "\tCompletion Tokens: 225\n",
      "Successful Requests: 3\n",
      "Total Cost (USD): $0.33174\n"
     ]
    }
   ],
   "source": [
    "langchain.debug=False\n",
    "with get_openai_callback() as cb:\n",
    "    print(q1)\n",
    "    run_agent_simple(q1)\n",
    "    print(cb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "37505a73",
   "metadata": {},
   "source": [
    "# Old Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "9d5e3212",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tools = [run_sparql_query.tool] + [taxon_agent] + [SchemaClass.tool, NPCClass.tool]#+ tool_extract_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "831581ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "general_template = \"\"\"\n",
    "You are trying to generate a SPARQL query for the Experiment Natural Products Knowledge Graph (ENPKG)based on a natural language question. Here are your instructions:\n",
    "\n",
    "1. Use IDTool for identifying pertinent URIs by inputting the question.\n",
    "2. Use ClassTool only if the question references a chemical class\n",
    "3. Use TaxonTool only if a taxon is mentioned. Input is a colon seperated list of length 2 with taxon:question to get URIs if any chemical classes are mentioned. \n",
    "4. Run sparql query with SparqlQueryRunner\n",
    "5. If no results first think about if the unknowns are of the expected rdfs:Class, otherwise tell the user how to improve their question \n",
    "\n",
    "Note:\n",
    "* IMPORTANT: pass a colon seperated list of length 2 into TaxonTool\n",
    "* DO NOT assume any identifiers \n",
    "* This is NOT the wikidata knowledge graph\n",
    "* Pay attention to whether URI is type 'entity' or 'predicate' when generating the sparql\n",
    "\n",
    "You can use this prefix (replace the start of the URI with the prefix):\n",
    "PREFIX enpkg: <https://enpkg.commons-lab.org/kg/>\n",
    "PREFIX enpkg_module: <https://enpkg.commons-lab.org/module/>\n",
    "\n",
    "Question: {question}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "id": "76a46efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "prompt = PromptTemplate(\n",
    "    template=general_template,\n",
    "    input_variables=[\"question\"]\n",
    ")\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-4\")\n",
    "agent = initialize_agent(all_tools, llm, agent=AgentType.OPENAI_FUNCTIONS, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17c508d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = 'How many features (pos ionization and neg ionization modes) have the same SIRIUS/CSI:FingerID and ISDB annotation by comparing the InCHIKey of the annotations?'\n",
    "q2 = 'Which samples have features (pos ionization mode) annotated as the class, aspidosperma-type alkaloids, by CANOPUS with a probability score above 0.5, ordered by the decresing count of features as aspidosperma-type alkaloids? Group by extract sample.'\n",
    "q3 = 'Among the structural annotations from the Tabernaemontana coffeoides (Apocynaceae) seeds extract taxon , which ones contain an aspidospermidine substructure, CCC12CCCN3C1C4(CC3)C(CC2)NC5=CC=CC=C45?'\n",
    "q3_og = 'Among the structural annotations from the Tabernaemontana coffeoides (Apocynaceae) seeds extract taxon , which ones contain an aspidospermidine substructure?'\n",
    "q4 = 'Among the SIRIUS structural annotations from the Tabernaemontana coffeoides (Apocynaceae) seeds extract taxon, which ones are reported in the Tabernaemontana genus in Wikidata? Can use service <https://query.wikidata.org/sparql> to run a subquery to wikidata within the sparql query'\n",
    "q5 = 'Which compounds annotated in the active extract of the Melochia umbellata taxon have activity against T. cruzi reported (in ChEMBL) by looking at the cosmic, zdiac and taxo scores?'\n",
    "q6 = 'Which features have the most fragments and neutral losses in common with feature #1 from the aerial part in PI mode (the [M+H] ion of walterione G in this extract)?'\n",
    "q7 = 'Filter the pos ionization mode features of the Melochia umbellata taxon annotated as [M+H]+ by SIRIUS to keep the ones for which a feature in neg ionization mode is detected with the same retention time (+/- 3 seconds) and a mass corresponding to the [M-H]- adduct (+/- 5ppm).'\n",
    "q8 = 'For features from the Melochia umbellata taxon in pos ionization mode with SIRIUS annotations, get the ones for which a feature in neg ionization mode with the same retention time (+/- 3 seconds) has the same SIRIUS annotation by comparing the InCHIKey 2D.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfad8761",
   "metadata": {},
   "outputs": [],
   "source": [
    "q9 = \"How many extracts exist for each taxon (submitted taxon), and among these nodes, how many have cross-references to Wikidata (WD)?\"\n",
    "q10 = \"Which features were annotated as 'Tetraketide meroterpenoids' by SIRIUS, and how many such features were found for each species and plant part?\"\n",
    "q11 = \"What are all distinct taxons for the extracts in the knowledge graph?\"\n",
    "q12 = \"What are the taxons, lab process and label (if one exists) for each sample?\"\n",
    "q13 = None\n",
    "q14 = \"What compounds from the Tabernaemontana coffeoides taxon or its siblings in Wikidata have sirius annotations and other features in our knowledge graph? Match based on molecular formula.\"\n",
    "q15 = \"Given a specific taxon, can we identify all the chemical compounds found in this taxon or its siblings in Wikidata, that also have associated mass spectrometry data and molecular formula annotations from SIRIUS? Returning only those that have matching molecular formulas.\"\n",
    "q16 = \"Count all the species per family in the collection\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
