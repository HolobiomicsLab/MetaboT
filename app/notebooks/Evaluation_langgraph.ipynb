{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T13:53:32.635392Z",
     "start_time": "2024-05-15T13:53:32.631126Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load the environment variables from the .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T13:46:57.285945Z",
     "start_time": "2024-05-15T13:46:57.168392Z"
    }
   },
   "outputs": [
    {
     "ename": "LangSmithUserError",
     "evalue": "API key must be provided when using hosted LangSmith API",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mLangSmithUserError\u001B[0m                        Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 12\u001B[0m\n\u001B[1;32m      9\u001B[0m os\u001B[38;5;241m.\u001B[39menviron[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLANGCHAIN_ENDPOINT\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps://api.smith.langchain.com\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlangsmith\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Client\n\u001B[0;32m---> 12\u001B[0m client \u001B[38;5;241m=\u001B[39m \u001B[43mClient\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;66;03m# #Check if the client was initialized\u001B[39;00m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28mprint\u001B[39m(client)\n",
      "File \u001B[0;32m~/anaconda3/envs/kgai/lib/python3.11/site-packages/langsmith/client.py:414\u001B[0m, in \u001B[0;36mClient.__init__\u001B[0;34m(self, api_url, api_key, retry_config, timeout_ms, web_url, session, auto_batch_tracing)\u001B[0m\n\u001B[1;32m    412\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapi_key \u001B[38;5;241m=\u001B[39m _get_api_key(api_key)\n\u001B[1;32m    413\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapi_url \u001B[38;5;241m=\u001B[39m _get_api_url(api_url, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapi_key)\n\u001B[0;32m--> 414\u001B[0m \u001B[43m_validate_api_key_if_hosted\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapi_url\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapi_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    415\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mretry_config \u001B[38;5;241m=\u001B[39m retry_config \u001B[38;5;129;01mor\u001B[39;00m _default_retry_config()\n\u001B[1;32m    416\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtimeout_ms \u001B[38;5;241m=\u001B[39m timeout_ms \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;241m10000\u001B[39m\n",
      "File \u001B[0;32m~/anaconda3/envs/kgai/lib/python3.11/site-packages/langsmith/client.py:265\u001B[0m, in \u001B[0;36m_validate_api_key_if_hosted\u001B[0;34m(api_url, api_key)\u001B[0m\n\u001B[1;32m    263\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m api_key:\n\u001B[1;32m    264\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _is_langchain_hosted(api_url):\n\u001B[0;32m--> 265\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m ls_utils\u001B[38;5;241m.\u001B[39mLangSmithUserError(\n\u001B[1;32m    266\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAPI key must be provided when using hosted LangSmith API\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    267\u001B[0m         )\n",
      "\u001B[0;31mLangSmithUserError\u001B[0m: API key must be provided when using hosted LangSmith API"
     ]
    }
   ],
   "source": [
    "# #Setting up the LangSmith\n",
    "# #For now, all runs will be stored in the \"KGBot Testing - GPT4\"\n",
    "# #If you want to separate the traces to have a better control of specific traces.\n",
    "# #Metadata as llm version and temperature can be obtained from traces.\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = (\n",
    "    f\"KGBot Testing - Interpreter_agent\"  # Please update the name here if you want to create a new project for separating the traces.\n",
    ")\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "from langsmith import Client\n",
    "\n",
    "client = Client()\n",
    "\n",
    "# #Check if the client was initialized\n",
    "print(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T09:03:51.490555Z",
     "start_time": "2024-03-26T09:03:51.486410Z"
    }
   },
   "outputs": [],
   "source": [
    "# langchain imports for agent and prompt handling\n",
    "from langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent, AgentOutputParser \n",
    "from langchain.prompts import BaseChatPromptTemplate\n",
    "from langchain.utilities import SerpAPIWrapper\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import create_openai_tools_agent\n",
    "from langchain import hub\n",
    "\n",
    "# langgraph imports for prebuilt tool invocation\n",
    "from langgraph.prebuilt import ToolInvocation\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# langchain_core imports for message handling and action schema\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, FunctionMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder \n",
    "from langchain.schema import AgentAction, AgentFinish, HumanMessage\n",
    "\n",
    "# langchain output parser for OpenAI functions\n",
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "from codeinterpreterapi import CodeInterpreterSession, File\n",
    "# typing imports for type hinting\n",
    "from typing import Annotated, List, Tuple, Union,  Any, Dict, Optional, Sequence, TypedDict\n",
    "import operator\n",
    "import functools\n",
    "\n",
    "# Standard library imports for JSON and regular expressions\n",
    "import json\n",
    "import re\n",
    "from importlib import reload\n",
    "import sparql  \n",
    "reload(sparql)\n",
    "# Custom imports for RDF graph manipulation and chemical, target, taxon, and SPARQL resolution\n",
    "from RdfGraphCustom import RdfGraph\n",
    "from smile_resolver import smiles_to_inchikey\n",
    "from chemical_resolver import ChemicalResolver\n",
    "from target_resolver import target_name_to_target_id\n",
    "from taxon_resolver import TaxonResolver\n",
    "from sparql import GraphSparqlQAChain\n",
    "\n",
    "# langchain pydantic for base model definitions\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "# langchain tools for base, structured tool definitions, and tool decorators\n",
    "from langchain.tools import BaseTool, StructuredTool, tool\n",
    "\n",
    "# Standard library import for object serialization\n",
    "import pickle\n",
    "\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Creating the Dataset for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T10:43:23.764543Z",
     "start_time": "2024-03-26T10:43:23.547358Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "[Errno 409 Client Error: Conflict for url: https://api.smith.langchain.com/datasets] {\"detail\":\"Dataset with this name already exists.\"}",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mHTTPError\u001B[0m                                 Traceback (most recent call last)",
      "File \u001B[0;32m~/anaconda3/envs/kgai/lib/python3.11/site-packages/langsmith/utils.py:102\u001B[0m, in \u001B[0;36mraise_for_status_with_text\u001B[0;34m(response)\u001B[0m\n\u001B[1;32m    101\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 102\u001B[0m     \u001B[43mresponse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mraise_for_status\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    103\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m requests\u001B[38;5;241m.\u001B[39mHTTPError \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m~/anaconda3/envs/kgai/lib/python3.11/site-packages/requests/models.py:1021\u001B[0m, in \u001B[0;36mResponse.raise_for_status\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1020\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m http_error_msg:\n\u001B[0;32m-> 1021\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m HTTPError(http_error_msg, response\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m)\n",
      "\u001B[0;31mHTTPError\u001B[0m: 409 Client Error: Conflict for url: https://api.smith.langchain.com/datasets",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mHTTPError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[70], line 31\u001B[0m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;66;03m# Creating the datasets for testing\u001B[39;00m\n\u001B[1;32m     29\u001B[0m dataset_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTesting q1_6\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m---> 31\u001B[0m dataset \u001B[38;5;241m=\u001B[39m \u001B[43mclient\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate_dataset\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     32\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdataset_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     33\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdescription\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mAn example dataset of questions to run\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     34\u001B[0m \u001B[43m)\u001B[49m\n\u001B[1;32m     36\u001B[0m client\u001B[38;5;241m.\u001B[39mcreate_examples(\n\u001B[1;32m     37\u001B[0m     inputs\u001B[38;5;241m=\u001B[39m[{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mquestion\u001B[39m\u001B[38;5;124m\"\u001B[39m: question} \u001B[38;5;28;01mfor\u001B[39;00m question \u001B[38;5;129;01min\u001B[39;00m dataset_inputs],\n\u001B[1;32m     38\u001B[0m     outputs\u001B[38;5;241m=\u001B[39m[{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutput\u001B[39m\u001B[38;5;124m\"\u001B[39m: answer} \u001B[38;5;28;01mfor\u001B[39;00m answer \u001B[38;5;129;01min\u001B[39;00m example_outputs],\n\u001B[1;32m     39\u001B[0m     dataset_id\u001B[38;5;241m=\u001B[39mdataset\u001B[38;5;241m.\u001B[39mid,\n\u001B[1;32m     40\u001B[0m )\n",
      "File \u001B[0;32m~/anaconda3/envs/kgai/lib/python3.11/site-packages/langsmith/client.py:2105\u001B[0m, in \u001B[0;36mClient.create_dataset\u001B[0;34m(self, dataset_name, description, data_type)\u001B[0m\n\u001B[1;32m   2095\u001B[0m dataset \u001B[38;5;241m=\u001B[39m ls_schemas\u001B[38;5;241m.\u001B[39mDatasetCreate(\n\u001B[1;32m   2096\u001B[0m     name\u001B[38;5;241m=\u001B[39mdataset_name,\n\u001B[1;32m   2097\u001B[0m     description\u001B[38;5;241m=\u001B[39mdescription,\n\u001B[1;32m   2098\u001B[0m     data_type\u001B[38;5;241m=\u001B[39mdata_type,\n\u001B[1;32m   2099\u001B[0m )\n\u001B[1;32m   2100\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msession\u001B[38;5;241m.\u001B[39mpost(\n\u001B[1;32m   2101\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapi_url \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/datasets\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   2102\u001B[0m     headers\u001B[38;5;241m=\u001B[39m{\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_headers, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mContent-Type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mapplication/json\u001B[39m\u001B[38;5;124m\"\u001B[39m},\n\u001B[1;32m   2103\u001B[0m     data\u001B[38;5;241m=\u001B[39mdataset\u001B[38;5;241m.\u001B[39mjson(),\n\u001B[1;32m   2104\u001B[0m )\n\u001B[0;32m-> 2105\u001B[0m \u001B[43mls_utils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mraise_for_status_with_text\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresponse\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2106\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m ls_schemas\u001B[38;5;241m.\u001B[39mDataset(\n\u001B[1;32m   2107\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mresponse\u001B[38;5;241m.\u001B[39mjson(),\n\u001B[1;32m   2108\u001B[0m     _host_url\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_host_url,\n\u001B[1;32m   2109\u001B[0m     _tenant_id\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_optional_tenant_id(),\n\u001B[1;32m   2110\u001B[0m )\n",
      "File \u001B[0;32m~/anaconda3/envs/kgai/lib/python3.11/site-packages/langsmith/utils.py:104\u001B[0m, in \u001B[0;36mraise_for_status_with_text\u001B[0;34m(response)\u001B[0m\n\u001B[1;32m    102\u001B[0m     response\u001B[38;5;241m.\u001B[39mraise_for_status()\n\u001B[1;32m    103\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m requests\u001B[38;5;241m.\u001B[39mHTTPError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m--> 104\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m requests\u001B[38;5;241m.\u001B[39mHTTPError(\u001B[38;5;28mstr\u001B[39m(e), response\u001B[38;5;241m.\u001B[39mtext) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n",
      "\u001B[0;31mHTTPError\u001B[0m: [Errno 409 Client Error: Conflict for url: https://api.smith.langchain.com/datasets] {\"detail\":\"Dataset with this name already exists.\"}"
     ]
    }
   ],
   "source": [
    "from langsmith.evaluation import EvaluationResult, run_evaluator\n",
    "from langchain.evaluation import EvaluatorType\n",
    "from langsmith.schemas import Example, Run\n",
    "from langchain.smith import run_on_dataset, RunEvalConfig\n",
    "dataset_inputs = [\n",
    "    \"How many features (pos ionization and neg ionization modes) have the same SIRIUS/CSI:FingerID and ISDB annotation by comparing the InCHIKey2D of the annotations?\",\n",
    "    #\"Which samples have features (positive ionization mode) annotated as aspidosperma-type alkaloids by CANOPUS with a probability score above 0.5, ordered by the decreasing count of features as aspidosperma-type alkaloids?\",\n",
    "   # \"Among the structural annotations from Tabernaemontana coffeoides (Apocynaceae) seeds extract, which ones contain an aspidospermidine substructure?\",\n",
    "    #\"Among the SIRIUS structural annotations from Tabernaemontana coffeoides (Apocynaceae) seeds extract, which ones are reported in the Tabernaemontana genus in WD?\",\n",
    "    #\"Which compounds annotated in the active extract of Melochia umbellata have activity against T. cruzi reported (in ChEMBL), and in which taxon they are reported (in Wikidata)?\",\n",
    "    #\"Filter the positive ionization mode features of Melochia umbellata annotated as [M+H]+ by SIRIUS to keep the ones for which a feature in negative ionization mode is detected with the same retention time (± 3 seconds) and a mass corresponding to the [M-H]- adduct (± 5 ppm)\",\n",
    "    #\"For features from Melochia umbellata in positive mode mode with SIRIUS annotations, get the ones for which a feature in negative ionization mode with the same retention time (± 3 sec) has the same SIRIUS annotation (2D IK).\"\n",
    "]\n",
    "\n",
    "example_outputs = [\n",
    "    \"The number of features (in both positive and negative ionization modes) that have the same SIRIUS/CSI:FingerID and ISDB annotation, as determined by comparing the InCHIKey2D of the annotations, is 33,255.\",\n",
    "    #\"The extracts that have features (pos ionization mode) annotated as the class, aspidosperma-type alkaloids, by CANOPUS with a probability score above 0.5, ordered by the decreasing count of features as aspidosperma-type alkaloids are:\n",
    "\n",
    "\n",
    "    #\"3 distinct stereochemically undefined structures (2D InChiKey) that contain an aspidospermidine substructure: COC(=O)C1=C2Nc3ccccc3C23CCN2CC4(CC5CC67CC(=O)OC6CCN6CCC8(c9cccc(OC)c9N(C4)C58O)C67)C4OCCC4(C1)C23, COC(=O)C1CC23CCC[N+]4(C2C5(C1(CC3)NC6=CC=CC=C65)CC4)[O-], COC(=O)C1=C2Nc3ccccc3C23CCN2C3C3(CCOC3C3CC4CC56CCOC5CCN5CCC7(c8cccc(OC)c8NC47C32)C56)C1.\",\n",
    "    #\"18 distinct stereochemically undefined structures annotated by SIRIUS in Tabernaemontana coffeoides (Apocynaceae) seeds extract and reported in at least one Tabernaemontana sp.\",\n",
    "    #\"14 distinct stereochemically undefined structures, all of them reported in Waltheria indica.\",\n",
    "    #\"62 features from Melochia umbellata in positive ionization mode annotated as [M+H]+ by SIRIUS with their corresponding potential [M-H]\"\n",
    "    #\"22 features in positive ionization mode for which a feature in negative ionization mode with the same retention time has the same annotation.\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# Creating the datasets for testing\n",
    "\n",
    "dataset_name = \"Testing new gpt\"\n",
    "\n",
    "dataset = client.create_dataset(\n",
    "    dataset_name,\n",
    "    description=\"An example dataset of questions to run\",\n",
    ")\n",
    "\n",
    "client.create_examples(\n",
    "    inputs=[{\"question\": question} for question in dataset_inputs],\n",
    "    outputs=[{\"output\": answer} for answer in example_outputs],\n",
    "    dataset_id=dataset.id,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T10:27:02.313098Z",
     "start_time": "2024-03-26T10:27:02.307220Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing q1_6\n"
     ]
    }
   ],
   "source": [
    "print(dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Defining evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T10:27:03.972240Z",
     "start_time": "2024-03-26T10:27:03.962127Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Defining a custom evaluator that checks if the generated answer is uninformative\n",
    "\n",
    "@run_evaluator\n",
    "def check_not_idk(run: Run, example: Example):\n",
    "    \"\"\"Illustration of a custom evaluator.\"\"\"\n",
    "    agent_response = run.outputs[\"output\"]\n",
    "    if \"don't know\" in agent_response or \"not sure\" in agent_response:\n",
    "        score = 0\n",
    "    else:\n",
    "        score = 1\n",
    "    # You can access the dataset labels in example.outputs[key]\n",
    "    # You can also access the model inputs in run.inputs[key]\n",
    "    return EvaluationResult(\n",
    "        key=\"not_uncertain\",\n",
    "        score=score,\n",
    "    )\n",
    "# Defining the proper evaluation\n",
    "\n",
    "evaluation_config = RunEvalConfig(\n",
    "    # Evaluators can either be an evaluator type (e.g., \"qa\", \"criteria\", \"embedding_distance\", etc.) or a configuration for that evaluator\n",
    "    evaluators=[\n",
    "        # Measures whether a QA response is \"Correct\", based on a reference answer\n",
    "        # You can also select via the raw string \"qa\"\n",
    "        EvaluatorType.QA,\n",
    "        # Measure the embedding distance between the output and the reference answer\n",
    "        # Equivalent to: EvalConfig.EmbeddingDistance(embeddings=OpenAIEmbeddings())\n",
    "        \n",
    "        # Grade whether the output satisfies the stated criteria.\n",
    "        # You can select a default one such as \"helpfulness\" or provide your own.\n",
    "        RunEvalConfig.LabeledCriteria(\"helpfulness\"),\n",
    "        # The LabeledScoreString evaluator outputs a score on a scale from 1-10.\n",
    "        # You can use default criteria or write our own rubric\n",
    "        RunEvalConfig.LabeledScoreString(\n",
    "            {\n",
    "                \"accuracy\": \"\"\"\n",
    "Score 1: The answer is completely unrelated to the reference.\n",
    "Score 3: The answer has minor relevance but does not align with the reference.\n",
    "Score 5: The answer has moderate relevance but contains inaccuracies.\n",
    "Score 7: The answer aligns with the reference but has minor errors or omissions.\n",
    "Score 10: The answer is completely accurate and aligns perfectly with the reference.\"\"\"\n",
    "            },\n",
    "            #normalize_by=10,\n",
    "        ),\n",
    "    ],\n",
    "    # You can add custom StringEvaluator or RunEvaluator objects here as well, which will automatically be\n",
    "    # applied to each prediction. Check out the docs for examples.\n",
    "    custom_evaluators=[check_not_idk],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/madinabekbergenova/Desktop/LLMs/kgbot_dev_new/app\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/madinabekbergenova/anaconda3/envs/kgai/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for ChatOpenAI\n__root__\n  Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. (type=value_error)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValidationError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 8\u001B[0m\n\u001B[1;32m      6\u001B[0m endpoint_url \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps://enpkg.commons-lab.org/graphdb/repositories/ENPKG\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      7\u001B[0m graph \u001B[38;5;241m=\u001B[39m link_kg_database(endpoint_url)\n\u001B[0;32m----> 8\u001B[0m models \u001B[38;5;241m=\u001B[39m \u001B[43mllm_creation\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      9\u001B[0m agents \u001B[38;5;241m=\u001B[39m create_all_agents(models, graph)\n\u001B[1;32m     10\u001B[0m app \u001B[38;5;241m=\u001B[39m create_workflow(agents)\n",
      "File \u001B[0;32m~/Desktop/LLMs/kgbot_dev_new/app/core/main.py:64\u001B[0m, in \u001B[0;36mllm_creation\u001B[0;34m()\u001B[0m\n\u001B[1;32m     62\u001B[0m     model_id \u001B[38;5;241m=\u001B[39m config[section][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mid\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m     63\u001B[0m     max_retries \u001B[38;5;241m=\u001B[39m config[section][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmax_retries\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m---> 64\u001B[0m     llm \u001B[38;5;241m=\u001B[39m \u001B[43mChatOpenAI\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     65\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtemperature\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtemperature\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     67\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_retries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_retries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     68\u001B[0m \u001B[43m        \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     69\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     70\u001B[0m     models[section] \u001B[38;5;241m=\u001B[39m llm\n\u001B[1;32m     72\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m models\n",
      "File \u001B[0;32m~/anaconda3/envs/kgai/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:180\u001B[0m, in \u001B[0;36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    178\u001B[0m     warned \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    179\u001B[0m     emit_warning()\n\u001B[0;32m--> 180\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mwrapped\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/kgai/lib/python3.11/site-packages/langchain_core/load/serializable.py:120\u001B[0m, in \u001B[0;36mSerializable.__init__\u001B[0;34m(self, **kwargs)\u001B[0m\n\u001B[1;32m    119\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 120\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    121\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lc_kwargs \u001B[38;5;241m=\u001B[39m kwargs\n",
      "File \u001B[0;32m~/anaconda3/envs/kgai/lib/python3.11/site-packages/pydantic/v1/main.py:341\u001B[0m, in \u001B[0;36mBaseModel.__init__\u001B[0;34m(__pydantic_self__, **data)\u001B[0m\n\u001B[1;32m    339\u001B[0m values, fields_set, validation_error \u001B[38;5;241m=\u001B[39m validate_model(__pydantic_self__\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m, data)\n\u001B[1;32m    340\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m validation_error:\n\u001B[0;32m--> 341\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m validation_error\n\u001B[1;32m    342\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    343\u001B[0m     object_setattr(__pydantic_self__, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m__dict__\u001B[39m\u001B[38;5;124m'\u001B[39m, values)\n",
      "\u001B[0;31mValidationError\u001B[0m: 1 validation error for ChatOpenAI\n__root__\n  Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. (type=value_error)"
     ]
    }
   ],
   "source": [
    "from app.core.agents.agents_factory import create_all_agents\n",
    "from app.core.workflow.langraph_workflow import create_workflow, process_workflow\n",
    "from app.core.graph_management.RdfGraphCustom import RdfGraph\n",
    "from app.core.main import link_kg_database\n",
    "from app.core.main import llm_creation\n",
    "endpoint_url = \"https://enpkg.commons-lab.org/graphdb/repositories/ENPKG\"\n",
    "graph = link_kg_database(endpoint_url)\n",
    "models = llm_creation()\n",
    "agents = create_all_agents(models, graph)\n",
    "app = create_workflow(agents)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-15T13:46:13.975471Z",
     "start_time": "2024-05-15T13:46:12.770791Z"
    }
   },
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T10:27:14.195912Z",
     "start_time": "2024-03-26T10:27:04.796768Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-26 11:27:04,819 - INFO - query \n",
      "    SELECT DISTINCT ?cls ?com ?label\n",
      "        WHERE {\n",
      "            ?cls a rdfs:Class . \n",
      "            OPTIONAL { ?cls rdfs:comment ?com }\n",
      "            OPTIONAL { ?cls rdfs:label ?label }\n",
      "        }\n",
      "        GROUP BY ?cls ?com ?label\n",
      "    \n",
      "Adding classes to graph: 100%|██████████| 50/50 [00:09<00:00,  5.40it/s]\n",
      "2024-03-26 11:27:14,165 - INFO - namespaces [('brick', 'https://brickschema.org/schema/Brick#'), ('csvw', 'http://www.w3.org/ns/csvw#'), ('dc', 'http://purl.org/dc/elements/1.1/'), ('dcat', 'http://www.w3.org/ns/dcat#'), ('dcmitype', 'http://purl.org/dc/dcmitype/'), ('dcterms', 'http://purl.org/dc/terms/'), ('dcam', 'http://purl.org/dc/dcam/'), ('doap', 'http://usefulinc.com/ns/doap#'), ('foaf', 'http://xmlns.com/foaf/0.1/'), ('geo', 'http://www.opengis.net/ont/geosparql#'), ('odrl', 'http://www.w3.org/ns/odrl/2/'), ('org', 'http://www.w3.org/ns/org#'), ('prof', 'http://www.w3.org/ns/dx/prof/'), ('prov', 'http://www.w3.org/ns/prov#'), ('qb', 'http://purl.org/linked-data/cube#'), ('schema', 'https://schema.org/'), ('sh', 'http://www.w3.org/ns/shacl#'), ('skos', 'http://www.w3.org/2004/02/skos/core#'), ('sosa', 'http://www.w3.org/ns/sosa/'), ('ssn', 'http://www.w3.org/ns/ssn/'), ('time', 'http://www.w3.org/2006/time#'), ('vann', 'http://purl.org/vocab/vann/'), ('void', 'http://rdfs.org/ns/void#'), ('wgs', 'https://www.w3.org/2003/01/geo/wgs84_pos#'), ('owl', 'http://www.w3.org/2002/07/owl#'), ('rdf', 'http://www.w3.org/1999/02/22-rdf-syntax-ns#'), ('rdfs', 'http://www.w3.org/2000/01/rdf-schema#'), ('xsd', 'http://www.w3.org/2001/XMLSchema#'), ('xml', 'http://www.w3.org/XML/1998/namespace'), ('ns1', 'https://enpkg.commons-lab.org/kg/'), ('ns2', 'https://enpkg.commons-lab.org/module/')]\n",
      "2024-03-26 11:27:14,170 - INFO - number of tokens 5893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The namespace prefixes are: [('brick', 'https://brickschema.org/schema/Brick#'), ('csvw', 'http://www.w3.org/ns/csvw#'), ('dc', 'http://purl.org/dc/elements/1.1/'), ('dcat', 'http://www.w3.org/ns/dcat#'), ('dcmitype', 'http://purl.org/dc/dcmitype/'), ('dcterms', 'http://purl.org/dc/terms/'), ('dcam', 'http://purl.org/dc/dcam/'), ('doap', 'http://usefulinc.com/ns/doap#'), ('foaf', 'http://xmlns.com/foaf/0.1/'), ('geo', 'http://www.opengis.net/ont/geosparql#'), ('odrl', 'http://www.w3.org/ns/odrl/2/'), ('org', 'http://www.w3.org/ns/org#'), ('prof', 'http://www.w3.org/ns/dx/prof/'), ('prov', 'http://www.w3.org/ns/prov#'), ('qb', 'http://purl.org/linked-data/cube#'), ('schema', 'https://schema.org/'), ('sh', 'http://www.w3.org/ns/shacl#'), ('skos', 'http://www.w3.org/2004/02/skos/core#'), ('sosa', 'http://www.w3.org/ns/sosa/'), ('ssn', 'http://www.w3.org/ns/ssn/'), ('time', 'http://www.w3.org/2006/time#'), ('vann', 'http://purl.org/vocab/vann/'), ('void', 'http://rdfs.org/ns/void#'), ('wgs', 'https://www.w3.org/2003/01/geo/wgs84_pos#'), ('owl', 'http://www.w3.org/2002/07/owl#'), ('rdf', 'http://www.w3.org/1999/02/22-rdf-syntax-ns#'), ('rdfs', 'http://www.w3.org/2000/01/rdf-schema#'), ('xsd', 'http://www.w3.org/2001/XMLSchema#'), ('xml', 'http://www.w3.org/XML/1998/namespace'), ('ns1', 'https://enpkg.commons-lab.org/kg/'), ('ns2', 'https://enpkg.commons-lab.org/module/')]\n",
      "In the following, each URI is followed by the local name and optionally its rdfs:Label, and optionally its rdfs:comment. \n",
      "The RDF graph supports the following node types:\n",
      "<rdf:XMLLiteral> (XMLLiteral, , ), <xsd:nonNegativeInteger> (nonNegativeInteger, , ), <xsd:string> (string, , ), <ns1:RawMaterial> (RawMaterial, A RawMaterial, A raw laboratory biological material, i.e. before extraction), <ns1:LFpair> (LFpair, pair of LCMSFeature, A pair of 2 LCMSFeature), <ns1:WDChemical> (WDChemical, Cross-reference to a chemical entity in Wikidata, Cross-reference to a chemical entity in Wikidata), <ns1:WDTaxon> (WDTaxon, Cross-reference to a taxon in Wikidata, Cross-reference to a taxon in Wikidata), <ns1:InChIkey2D> (InChIkey2D, 2D InChIKey, The first 14 characters of an InChIKey, often returned by MS-based annotation tools), <ns1:InChIkey> (InChIkey, InChIKey, A chemical structure represented by its InChIKey), <ns1:LabExtract> (LabExtract, A LabExtract, A natural extract obtained from the processing of a RawMaterial), <ns1:LCMSAnalysisPos> (LCMSAnalysisPos, Pos LCMS analysis, An LCMS analysis in positive ionization mode (pos)), <ns1:LCMSFeatureList> (LCMSFeatureList, Feature list, A list of LCMS features obtained from the processing of a given LCMS analysis), <ns1:SiriusCanopusAnnotation> (SiriusCanopusAnnotation, CANOPUS chemical class annotation, A spectrum chemical class annotation by SIRIUS-CANOPUS), <ns1:LCMSFeature> (LCMSFeature, LCMS individual MS2 spectrum, An LCMS feature from a processed LCMS analysis), <ns1:Spec2VecLoss> (Spec2VecLoss, A Spec2VecLoss, A Spec2VecLoss that partly characterizes an MS2Spectrum), <ns1:NPCClass> (NPCClass, NPCClass, A NPClassifier (NPC) chemical class), <ns1:NPCSuperclass> (NPCSuperclass, NPCSuperclass, A NPClassifier (NPC) chemical superclass), <ns1:Spec2VecPeak> (Spec2VecPeak, A Spec2VecPeak, A Spec2VecPeak that partly characterizes an MS2 spectrum), <ns1:SiriusStructureAnnotation> (SiriusStructureAnnotation, SIRIUS structural annotation, A spectrum structural annotation by SIRIUS), <ns1:Spec2VecDoc> (Spec2VecDoc, A Spec2VecDoc, An ensemble of Spec2VecPeak and Spec2VecLoss objects that characterizes an MS2Spectrum), <ns1:IsdbAnnotation> (IsdbAnnotation, ISDB structural annotation, A spectrum structural annotation by comparison with an in-silico spectral DB, coupled to chemical and taxonomical reweighting), <ns1:NPCPathway> (NPCPathway, NPCPathway, A NPClassifier (NPC) chemical pathway), <ns1:LCMSAnalysisNeg> (LCMSAnalysisNeg, Neg LCMS analysis, An LCMS analysis in negative ionization mode (neg)), <ns2:L610ugml> (L610ugml, L610ugml, A screening result at 10ug/mL from a phenotypic assay against L6 cells), <ns2:Ldono10ugml> (Ldono10ugml, Ldono10ugml, A screening result at 10ug/mL from a phenotypic assay against L.donovani), <ns2:Ldono2ugml> (Ldono2ugml, Ldono2ugml, A screening result at 2ug/mL from a phenotypic assay against L.donovani), <ns2:Tbrucei10ugml> (Tbrucei10ugml, Tbrucei10ugml, A screening result at 10ug/mL from a phenotypic assay against T.brucei rhodesiense), <ns2:Tbrucei2ugml> (Tbrucei2ugml, Tbrucei2ugml, A screening result at 2ug/mL from a phenotypic assay against T.brucei rhodesiense), <ns2:Tcruzi10ugml> (Tcruzi10ugml, Tcruzi10ugml, A screening result at 10ug/mL from a phenotypic assay against T.cruzi), <ns2:ChEMBLTarget> (ChEMBLTarget, A ChEMBL target, A ChEMBL target), <ns1:LabBlank> (LabBlank, A LabBlank, A blank sample), <ns1:LabQc> (LabQc, A LabQc, A quality control (QC) sample), <ns2:ChEMBLAssayResults> (ChEMBLAssayResults, A ChEMBL assay result, A ChEMBL assay result), <ns2:ChEMBLAssay> (ChEMBLAssay, A ChEMBL assay, A ChEMBL assay), <ns2:ChEMBLChemical> (ChEMBLChemical, A ChEMBL chemical, A ChEMBL chemical), <ns2:ChEMBLDocument> (ChEMBLDocument, A ChEMBL document, A ChEMBL document), <ns1:LabObject> (LabObject, A LabObject, An object that correspond to a physical laboratory object), <ns1:BioAssayResults> (BioAssayResults, A bioassay result, An object to store bioactivity results), <ns1:MS2Spectrum> (MS2Spectrum, MS2 spectrum, A fragmentation mass spectrometry (or MS2) spectrum), <ns1:LCMSAnalysis> (LCMSAnalysis, LCMS analysis, An LCMS analysis in a given ionization mode (pos or neg)), <ns1:Annotation> (Annotation, Spectrum annotation, A spectral annotation), <ns1:GNPSAnnotation> (GNPSAnnotation, GNPS structural annotation, A spectrum structural annotation by GNPS), <ns1:SpectralPair> (SpectralPair, pair of MS2Spectra, A pair of 2 MS2Spectra), <ns1:ChemicalEntity> (ChemicalEntity, chemical entity, ), <ns1:ChemicalEntity> (ChemicalEntity, A chemical entity (chemical structure or class), ), <ns1:ChemicalTaxonomy> (ChemicalTaxonomy, chemical taxonomy, ), <ns1:ChemicalTaxonomy> (ChemicalTaxonomy, A chemical taxonmy (chemical class), ), <ns1:XRef> (XRef, Any cross-reference, Any cross-reference), <ns1:spec2vec> (spec2vec, A spec2vec-related object, A spec2vec-related object), <ns2:SwissTPHBioAssay> (SwissTPHBioAssay, SwissTPHBioAssay, A bioasay result from Swiss Tropical and Public Health Institute (sTPH))\n",
      "The RDF graph have the following schema:\n",
      "@prefix ns1: <https://enpkg.commons-lab.org/kg/> .\n",
      "@prefix ns2: <https://enpkg.commons-lab.org/module/> .\n",
      "@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n",
      "@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\n",
      "\n",
      "ns1:LFpair ns1:has_cosine xsd:float ;\n",
      "    ns1:has_mass_difference xsd:float ;\n",
      "    ns1:has_member ns1:LCMSFeature,\n",
      "        ns1:MS2Spectrum ;\n",
      "    ns1:has_mn_params [ ] .\n",
      "\n",
      "ns1:LabBlank rdfs:label xsd:string ;\n",
      "    ns1:has_LCMS ns1:LCMSAnalysis,\n",
      "        ns1:LCMSAnalysisNeg .\n",
      "\n",
      "ns1:LabQc rdfs:label xsd:string ;\n",
      "    ns1:has_LCMS ns1:LCMSAnalysis,\n",
      "        ns1:LCMSAnalysisNeg .\n",
      "\n",
      "ns1:RawMaterial ns1:has_LCMS xsd:string,\n",
      "        ns1:WDTaxon,\n",
      "        ns1:XRef ;\n",
      "    ns1:has_lab_process ns1:LabExtract,\n",
      "        ns1:LabObject ;\n",
      "    ns1:has_lcms_feature_list xsd:string,\n",
      "        ns1:LabExtract,\n",
      "        ns1:LabObject,\n",
      "        ns1:WDTaxon,\n",
      "        ns1:XRef ;\n",
      "    ns1:has_sirius_annotation xsd:string,\n",
      "        ns1:LabExtract,\n",
      "        ns1:LabObject,\n",
      "        ns1:WDTaxon,\n",
      "        ns1:XRef ;\n",
      "    ns1:has_unresolved_taxon [ ] ;\n",
      "    ns1:has_wd_id ns1:WDTaxon,\n",
      "        ns1:XRef ;\n",
      "    ns1:submitted_taxon xsd:string ;\n",
      "    ns2:has_broad_organe [ ] ;\n",
      "    ns2:has_organe [ ] ;\n",
      "    ns2:has_subsystem [ ] ;\n",
      "    ns2:has_tissue [ ] .\n",
      "\n",
      "ns1:SpectralPair ns1:has_cosine xsd:float ;\n",
      "    ns1:has_mass_difference xsd:float ;\n",
      "    ns1:has_member ns1:LCMSFeature,\n",
      "        ns1:MS2Spectrum ;\n",
      "    ns1:has_mn_params [ ] .\n",
      "\n",
      "ns1:ChemicalEntity ns1:has_npc_class ns1:ChemicalTaxonomy,\n",
      "        ns1:NPCClass,\n",
      "        ns1:NPCPathway,\n",
      "        ns1:NPCSuperclass ;\n",
      "    ns1:has_npc_pathway ns1:ChemicalTaxonomy,\n",
      "        ns1:NPCClass,\n",
      "        ns1:NPCPathway,\n",
      "        ns1:NPCSuperclass ;\n",
      "    ns1:has_npc_superclass ns1:ChemicalTaxonomy,\n",
      "        ns1:NPCClass,\n",
      "        ns1:NPCPathway,\n",
      "        ns1:NPCSuperclass ;\n",
      "    ns1:has_smiles xsd:string ;\n",
      "    ns1:has_wd_id ns1:WDChemical,\n",
      "        ns1:XRef ;\n",
      "    ns2:has_chembl_id ns1:XRef,\n",
      "        ns2:ChEMBLChemical .\n",
      "\n",
      "ns1:InChIkey ns1:has_npc_class ns1:ChemicalTaxonomy,\n",
      "        ns1:NPCClass,\n",
      "        ns1:NPCPathway,\n",
      "        ns1:NPCSuperclass ;\n",
      "    ns1:has_npc_pathway ns1:ChemicalTaxonomy,\n",
      "        ns1:NPCClass,\n",
      "        ns1:NPCPathway,\n",
      "        ns1:NPCSuperclass ;\n",
      "    ns1:has_npc_superclass ns1:ChemicalTaxonomy,\n",
      "        ns1:NPCClass,\n",
      "        ns1:NPCPathway,\n",
      "        ns1:NPCSuperclass ;\n",
      "    ns1:has_smiles xsd:string ;\n",
      "    ns1:has_wd_id ns1:WDChemical,\n",
      "        ns1:XRef ;\n",
      "    ns2:has_chembl_id ns1:XRef,\n",
      "        ns2:ChEMBLChemical .\n",
      "\n",
      "ns2:ChEMBLAssayResults rdfs:label xsd:string ;\n",
      "    ns2:activity_relation xsd:string ;\n",
      "    ns2:activity_type xsd:string ;\n",
      "    ns2:activity_unit xsd:string ;\n",
      "    ns2:activity_value xsd:float ;\n",
      "    ns2:assay_id ns1:XRef,\n",
      "        ns2:ChEMBLAssay ;\n",
      "    ns2:stated_in_document ns1:XRef,\n",
      "        ns2:ChEMBLDocument ;\n",
      "    ns2:target_id ns1:XRef,\n",
      "        ns2:ChEMBLTarget ;\n",
      "    ns2:target_name xsd:string .\n",
      "\n",
      "ns2:ChEMBLDocument ns2:journal_name xsd:string .\n",
      "\n",
      "ns1:BioAssayResults rdfs:label xsd:string ;\n",
      "    ns2:inhibition_percentage xsd:float ;\n",
      "    ns2:target_id ns1:XRef,\n",
      "        ns2:ChEMBLTarget .\n",
      "\n",
      "ns1:SiriusCanopusAnnotation rdfs:label xsd:string ;\n",
      "    ns1:has_canopus_npc_class ns1:ChemicalTaxonomy,\n",
      "        ns1:NPCClass ;\n",
      "    ns1:has_canopus_npc_class_prob xsd:float ;\n",
      "    ns1:has_canopus_npc_pathway ns1:ChemicalTaxonomy,\n",
      "        ns1:NPCPathway ;\n",
      "    ns1:has_canopus_npc_pathway_prob xsd:float ;\n",
      "    ns1:has_canopus_npc_superclass ns1:ChemicalTaxonomy,\n",
      "        ns1:NPCSuperclass ;\n",
      "    ns1:has_canopus_npc_superclass_prob xsd:float .\n",
      "\n",
      "ns1:SiriusStructureAnnotation rdfs:label xsd:string ;\n",
      "    ns1:has_InChIkey2D ns1:InChIkey2D ;\n",
      "    ns1:has_cosmic_score xsd:float ;\n",
      "    ns1:has_ionization xsd:string ;\n",
      "    ns1:has_sirius_adduct xsd:string ;\n",
      "    ns1:has_sirius_score xsd:float ;\n",
      "    ns1:has_zodiac_score xsd:float .\n",
      "\n",
      "ns1:Spec2VecDoc rdfs:label xsd:string ;\n",
      "    ns1:has_spec2vec_loss ns1:Spec2VecLoss,\n",
      "        ns1:spec2vec ;\n",
      "    ns1:has_spec2vec_peak ns1:Spec2VecPeak,\n",
      "        ns1:spec2vec .\n",
      "\n",
      "ns1:Spec2VecLoss rdfs:label xsd:string ;\n",
      "    ns1:has_value xsd:float .\n",
      "\n",
      "ns1:Spec2VecPeak rdfs:label xsd:string ;\n",
      "    ns1:has_value xsd:float .\n",
      "\n",
      "ns2:ChEMBLChemical ns2:has_chembl_activity ns1:XRef,\n",
      "        ns2:ChEMBLAssayResults .\n",
      "\n",
      "ns2:L610ugml rdfs:label xsd:string ;\n",
      "    ns2:inhibition_percentage xsd:float .\n",
      "\n",
      "ns2:Ldono10ugml rdfs:label xsd:string ;\n",
      "    ns2:inhibition_percentage xsd:float ;\n",
      "    ns2:target_id ns1:XRef,\n",
      "        ns2:ChEMBLTarget .\n",
      "\n",
      "ns2:Ldono2ugml rdfs:label xsd:string ;\n",
      "    ns2:inhibition_percentage xsd:float ;\n",
      "    ns2:target_id ns1:XRef,\n",
      "        ns2:ChEMBLTarget .\n",
      "\n",
      "ns2:SwissTPHBioAssay rdfs:label xsd:string ;\n",
      "    ns2:inhibition_percentage xsd:float ;\n",
      "    ns2:target_id ns1:XRef,\n",
      "        ns2:ChEMBLTarget .\n",
      "\n",
      "ns2:Tbrucei10ugml rdfs:label xsd:string ;\n",
      "    ns2:inhibition_percentage xsd:float ;\n",
      "    ns2:target_id ns1:XRef,\n",
      "        ns2:ChEMBLTarget .\n",
      "\n",
      "ns2:Tbrucei2ugml rdfs:label xsd:string ;\n",
      "    ns2:inhibition_percentage xsd:float ;\n",
      "    ns2:target_id ns1:XRef,\n",
      "        ns2:ChEMBLTarget .\n",
      "\n",
      "ns2:Tcruzi10ugml rdfs:label xsd:string ;\n",
      "    ns2:inhibition_percentage xsd:float ;\n",
      "    ns2:target_id ns1:XRef,\n",
      "        ns2:ChEMBLTarget .\n",
      "\n",
      "ns1:InChIkey2D ns1:has_npc_class ns1:ChemicalTaxonomy,\n",
      "        ns1:NPCClass,\n",
      "        ns1:NPCPathway,\n",
      "        ns1:NPCSuperclass ;\n",
      "    ns1:has_npc_pathway ns1:ChemicalTaxonomy,\n",
      "        ns1:NPCClass,\n",
      "        ns1:NPCPathway,\n",
      "        ns1:NPCSuperclass ;\n",
      "    ns1:has_npc_superclass ns1:ChemicalTaxonomy,\n",
      "        ns1:NPCClass,\n",
      "        ns1:NPCPathway,\n",
      "        ns1:NPCSuperclass ;\n",
      "    ns1:has_smiles xsd:string ;\n",
      "    ns1:is_InChIkey2D_of ns1:ChemicalEntity,\n",
      "        ns1:InChIkey .\n",
      "\n",
      "ns1:LCMSFeature rdfs:label xsd:string ;\n",
      "    ns1:fast_search_gnpsdata_index_analog [ ] ;\n",
      "    ns1:fast_search_gnpsdata_index_no_analog [ ] ;\n",
      "    ns1:fast_search_gnpslibrary_analog [ ] ;\n",
      "    ns1:fast_search_gnpslibrary_no_analog [ ] ;\n",
      "    ns1:gnps_dashboard_view [ ] ;\n",
      "    ns1:has_canopus_annotation ns1:Annotation,\n",
      "        ns1:SiriusCanopusAnnotation ;\n",
      "    ns1:has_fbmn_ci [ ] ;\n",
      "    ns1:has_feature_area xsd:float ;\n",
      "    ns1:has_ionization xsd:string ;\n",
      "    ns1:has_isdb_annotation ns1:Annotation,\n",
      "        ns1:IsdbAnnotation ;\n",
      "    ns1:has_parent_mass xsd:float ;\n",
      "    ns1:has_raw_spectrum xsd:string ;\n",
      "    ns1:has_relative_feature_area xsd:float ;\n",
      "    ns1:has_retention_time xsd:float ;\n",
      "    ns1:has_row_id xsd:decimal ;\n",
      "    ns1:has_sirius_annotation ns1:Annotation,\n",
      "        ns1:IsdbAnnotation,\n",
      "        ns1:SiriusStructureAnnotation ;\n",
      "    ns1:has_spec2vec_doc ns1:Spec2VecDoc,\n",
      "        ns1:spec2vec ;\n",
      "    ns1:has_usi xsd:string .\n",
      "\n",
      "ns1:MS2Spectrum rdfs:label xsd:string ;\n",
      "    ns1:fast_search_gnpsdata_index_analog [ ] ;\n",
      "    ns1:fast_search_gnpsdata_index_no_analog [ ] ;\n",
      "    ns1:fast_search_gnpslibrary_analog [ ] ;\n",
      "    ns1:fast_search_gnpslibrary_no_analog [ ] ;\n",
      "    ns1:gnps_dashboard_view [ ] ;\n",
      "    ns1:has_canopus_annotation ns1:Annotation,\n",
      "        ns1:SiriusCanopusAnnotation ;\n",
      "    ns1:has_fbmn_ci [ ] ;\n",
      "    ns1:has_feature_area xsd:float ;\n",
      "    ns1:has_ionization xsd:string ;\n",
      "    ns1:has_isdb_annotation ns1:Annotation,\n",
      "        ns1:IsdbAnnotation ;\n",
      "    ns1:has_parent_mass xsd:float ;\n",
      "    ns1:has_raw_spectrum xsd:string ;\n",
      "    ns1:has_relative_feature_area xsd:float ;\n",
      "    ns1:has_retention_time xsd:float ;\n",
      "    ns1:has_row_id xsd:decimal ;\n",
      "    ns1:has_sirius_annotation ns1:Annotation,\n",
      "        ns1:IsdbAnnotation,\n",
      "        ns1:SiriusStructureAnnotation ;\n",
      "    ns1:has_spec2vec_doc ns1:Spec2VecDoc,\n",
      "        ns1:spec2vec ;\n",
      "    ns1:has_usi xsd:string .\n",
      "\n",
      "ns1:IsdbAnnotation rdfs:label xsd:string ;\n",
      "    ns1:has_InChIkey2D ns1:InChIkey2D ;\n",
      "    ns1:has_adduct xsd:string ;\n",
      "    ns1:has_consistency_score xsd:float ;\n",
      "    ns1:has_final_score xsd:float ;\n",
      "    ns1:has_spectral_score xsd:float ;\n",
      "    ns1:has_taxo_score xsd:float .\n",
      "\n",
      "ns1:LCMSAnalysisNeg ns1:has_gnpslcms_link [ ] ;\n",
      "    ns1:has_lcms_feature_list ns1:LCMSFeatureList ;\n",
      "    ns1:has_massive_doi [ ] ;\n",
      "    ns1:has_massive_license [ ] .\n",
      "\n",
      "ns1:LCMSFeatureList ns1:has_ionization xsd:string ;\n",
      "    ns1:has_lcms_feature ns1:LCMSFeature,\n",
      "        ns1:MS2Spectrum .\n",
      "\n",
      "ns1:Annotation rdfs:label xsd:string ;\n",
      "    ns1:has_InChIkey2D ns1:InChIkey2D ;\n",
      "    ns1:has_adduct xsd:string ;\n",
      "    ns1:has_canopus_npc_class ns1:ChemicalTaxonomy,\n",
      "        ns1:NPCClass ;\n",
      "    ns1:has_canopus_npc_class_prob xsd:float ;\n",
      "    ns1:has_canopus_npc_pathway ns1:ChemicalTaxonomy,\n",
      "        ns1:NPCPathway ;\n",
      "    ns1:has_canopus_npc_pathway_prob xsd:float ;\n",
      "    ns1:has_canopus_npc_superclass ns1:ChemicalTaxonomy,\n",
      "        ns1:NPCSuperclass ;\n",
      "    ns1:has_canopus_npc_superclass_prob xsd:float ;\n",
      "    ns1:has_consistency_score xsd:float ;\n",
      "    ns1:has_cosmic_score xsd:float ;\n",
      "    ns1:has_final_score xsd:float ;\n",
      "    ns1:has_ionization xsd:string ;\n",
      "    ns1:has_sirius_adduct xsd:string ;\n",
      "    ns1:has_sirius_score xsd:float ;\n",
      "    ns1:has_spectral_score xsd:float ;\n",
      "    ns1:has_taxo_score xsd:float ;\n",
      "    ns1:has_zodiac_score xsd:float .\n",
      "\n",
      "ns1:LCMSAnalysisPos ns1:has_gnpslcms_link [ ] ;\n",
      "    ns1:has_lcms_feature_list ns1:LCMSFeatureList ;\n",
      "    ns1:has_massive_doi [ ] ;\n",
      "    ns1:has_massive_license [ ] ;\n",
      "    ns1:has_sirius_annotation ns1:LCMSFeatureList .\n",
      "\n",
      "ns1:LabExtract rdfs:label xsd:string ;\n",
      "    ns1:has_LCMS ns1:LCMSAnalysis,\n",
      "        ns1:LCMSAnalysisNeg,\n",
      "        ns1:LCMSAnalysisPos ;\n",
      "    ns1:has_lcms_feature_list ns1:LCMSAnalysis,\n",
      "        ns1:LCMSAnalysisPos ;\n",
      "    ns1:has_sirius_annotation ns1:LCMSAnalysis,\n",
      "        ns1:LCMSAnalysisPos ;\n",
      "    ns2:has_bioassay_results ns1:BioAssayResults,\n",
      "        ns2:L610ugml,\n",
      "        ns2:Ldono10ugml,\n",
      "        ns2:Ldono2ugml,\n",
      "        ns2:SwissTPHBioAssay,\n",
      "        ns2:Tbrucei10ugml,\n",
      "        ns2:Tbrucei2ugml,\n",
      "        ns2:Tcruzi10ugml .\n",
      "\n",
      "ns1:LabObject rdfs:label xsd:string ;\n",
      "    ns1:has_LCMS xsd:string,\n",
      "        ns1:LCMSAnalysis,\n",
      "        ns1:LCMSAnalysisNeg,\n",
      "        ns1:LCMSAnalysisPos,\n",
      "        ns1:WDTaxon,\n",
      "        ns1:XRef ;\n",
      "    ns1:has_lab_process ns1:LabExtract,\n",
      "        ns1:LabObject ;\n",
      "    ns1:has_lcms_feature_list xsd:string,\n",
      "        ns1:LCMSAnalysis,\n",
      "        ns1:LCMSAnalysisPos,\n",
      "        ns1:LabExtract,\n",
      "        ns1:LabObject,\n",
      "        ns1:WDTaxon,\n",
      "        ns1:XRef ;\n",
      "    ns1:has_sirius_annotation xsd:string,\n",
      "        ns1:LCMSAnalysis,\n",
      "        ns1:LCMSAnalysisPos,\n",
      "        ns1:LabExtract,\n",
      "        ns1:LabObject,\n",
      "        ns1:WDTaxon,\n",
      "        ns1:XRef ;\n",
      "    ns1:has_unresolved_taxon [ ] ;\n",
      "    ns1:has_wd_id ns1:WDTaxon,\n",
      "        ns1:XRef ;\n",
      "    ns1:submitted_taxon xsd:string ;\n",
      "    ns2:has_bioassay_results ns1:BioAssayResults,\n",
      "        ns2:L610ugml,\n",
      "        ns2:Ldono10ugml,\n",
      "        ns2:Ldono2ugml,\n",
      "        ns2:SwissTPHBioAssay,\n",
      "        ns2:Tbrucei10ugml,\n",
      "        ns2:Tbrucei2ugml,\n",
      "        ns2:Tcruzi10ugml ;\n",
      "    ns2:has_broad_organe [ ] ;\n",
      "    ns2:has_organe [ ] ;\n",
      "    ns2:has_subsystem [ ] ;\n",
      "    ns2:has_tissue [ ] .\n",
      "\n",
      "ns1:spec2vec rdfs:label xsd:string ;\n",
      "    ns1:has_spec2vec_loss ns1:Spec2VecLoss,\n",
      "        ns1:spec2vec ;\n",
      "    ns1:has_spec2vec_peak ns1:Spec2VecPeak,\n",
      "        ns1:spec2vec ;\n",
      "    ns1:has_value xsd:float .\n",
      "\n",
      "ns1:LCMSAnalysis ns1:has_gnpslcms_link [ ] ;\n",
      "    ns1:has_lcms_feature_list ns1:LCMSFeatureList ;\n",
      "    ns1:has_massive_doi [ ] ;\n",
      "    ns1:has_massive_license [ ] ;\n",
      "    ns1:has_sirius_annotation ns1:LCMSFeatureList .\n",
      "\n",
      "ns2:ChEMBLTarget ns2:target_name xsd:string .\n",
      "\n",
      " \n"
     ]
    }
   ],
   "source": [
    "#from agent_supervisor import create_run_agent, process_stream\n",
    "#app = create_run_agent()\n",
    "def evaluate_result(_input):\n",
    "    message = {\n",
    "                \"messages\": [\n",
    "                    HumanMessage(content=_input[\"question\"])  # Assuming q2 is the content of the message\n",
    "                ]\n",
    "            }\n",
    "    response = app.invoke(message)\n",
    "    return {\"output\": response}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Defining chain_factory and running the evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T10:28:00.039845Z",
     "start_time": "2024-03-26T10:27:17.935471Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-26 11:27:17,934 - INFO - Wrapping function (_input) as RunnableLambda.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'Testing the app-7e7e7e38' at:\n",
      "https://smith.langchain.com/o/2830b3a1-2b4b-42fc-bc61-e5012f496ae5/datasets/094616d1-21f9-4a2d-b8f5-3fc704cd60cc/compare?selectedSessions=4126db01-c42f-4531-9147-db70718c7f39\n",
      "\n",
      "View all tests for Dataset Testing q1_6 at:\n",
      "https://smith.langchain.com/o/2830b3a1-2b4b-42fc-bc61-e5012f496ae5/datasets/094616d1-21f9-4a2d-b8f5-3fc704cd60cc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-26 11:27:18,368 - INFO - Wrapping function (_input) as RunnableLambda.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>                                                 ] 0/1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-26 11:27:19,911 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-03-26 11:27:21,250 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new GraphSparqlQAChain chain...\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-26 11:27:32,718 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated SPARQL:\n",
      "\u001B[32;1m\u001B[1;3mPREFIX ns1: <https://enpkg.commons-lab.org/kg/>\n",
      "PREFIX ns2: <https://enpkg.commons-lab.org/module/>\n",
      "SELECT (COUNT(DISTINCT ?feature) AS ?count)\n",
      "WHERE {\n",
      "    ?feature a ns1:LCMSFeature .\n",
      "    ?feature ns1:has_sirius_annotation ?siriusAnnotation .\n",
      "    ?siriusAnnotation a ns1:SiriusStructureAnnotation .\n",
      "    ?siriusAnnotation ns1:has_InChIkey2D ?inChIKey2D_sirius .\n",
      "    \n",
      "    ?feature ns1:has_isdb_annotation ?isdbAnnotation .\n",
      "    ?isdbAnnotation a ns1:IsdbAnnotation .\n",
      "    ?isdbAnnotation ns1:has_InChIkey2D ?inChIKey2D_isdb .\n",
      "    \n",
      "    FILTER (?inChIKey2D_sirius = ?inChIKey2D_isdb)\n",
      "}\u001B[0m\n",
      "Saving results to file:  /var/folders/20/4kgcw5656h12ss_nj18mndwm0000gn/T/tmpono_otf8.csv\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-26 11:27:35,308 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-03-26 11:27:59,856 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-03-26 11:27:59,885 - WARNING - Chain failed for example d1b9beb8-2267-4a31-945c-fa41a5ce12b2 with inputs {'question': 'How many features (pos ionization and neg ionization modes) have the same SIRIUS/CSI:FingerID and ISDB annotation by comparing the InCHIKey2D of the annotations?'}\n",
      "Error Type: TypeError, Message: 'HumanMessage' object is not subscriptable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[------------------------------------------------->] 1/1"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>Experiment Results:</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>error</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>run_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>'HumanMessage' object is not subscriptable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>984401a6-1010-42c7-9897-9fc989daf868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>41.456267</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>41.456267</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>41.456267</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>41.456267</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>41.456267</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>41.456267</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             error  execution_time  \\\n",
       "count                                            1        1.000000   \n",
       "unique                                           1             NaN   \n",
       "top     'HumanMessage' object is not subscriptable             NaN   \n",
       "freq                                             1             NaN   \n",
       "mean                                           NaN       41.456267   \n",
       "std                                            NaN             NaN   \n",
       "min                                            NaN       41.456267   \n",
       "25%                                            NaN       41.456267   \n",
       "50%                                            NaN       41.456267   \n",
       "75%                                            NaN       41.456267   \n",
       "max                                            NaN       41.456267   \n",
       "\n",
       "                                      run_id  \n",
       "count                                      1  \n",
       "unique                                     1  \n",
       "top     984401a6-1010-42c7-9897-9fc989daf868  \n",
       "freq                                       1  \n",
       "mean                                     NaN  \n",
       "std                                      NaN  \n",
       "min                                      NaN  \n",
       "25%                                      NaN  \n",
       "50%                                      NaN  \n",
       "75%                                      NaN  \n",
       "max                                      NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from uuid import uuid4\n",
    "unique_id = uuid4().hex[0:8]\n",
    "\n",
    "chain_results = run_on_dataset(\n",
    "    dataset_name=dataset_name,\n",
    "    llm_or_chain_factory=evaluate_result,\n",
    "    evaluation=evaluation_config,\n",
    "    verbose=True,\n",
    "    project_name=f\"Testing the app-{unique_id}\",\n",
    "    client=client,\n",
    "    # Project metadata communicates the experiment parameters,\n",
    "    # Useful for reviewing the test results\n",
    " project_metadata={\n",
    "    #     \"env\": \"testing-notebook\",\n",
    "         \"model\": \"gpt-4o\",\n",
    "    #     \"prompt\": \"5d466cbc\",\n",
    " },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T10:26:43.447884Z",
     "start_time": "2024-03-26T10:26:43.431075Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of features (in both positive and negative ionization modes) that have the same SIRIUS/CSI:FingerID and ISDB annotation, as determined by comparing the InCHIKey2D of the annotations, is 33,255.\n",
      "\n",
      "{\n",
      "  \"question\": \"How many features (pos ionization and neg ionization modes) have the same SIRIUS/CSI:FingerID and ISDB annotation by comparing the InCHIKey2D of the annotations?\",\n",
      "  \"generated_sparql_query\": \"PREFIX ns1: <https://enpkg.commons-lab.org/kg/>\\nSELECT (COUNT(DISTINCT ?feature) AS ?count)\\nWHERE {\\n    ?feature a ns1:LCMSFeature .\\n    ?feature ns1:has_sirius_annotation ?siriusAnnotation .\\n    ?feature ns1:has_isdb_annotation ?isdbAnnotation .\\n    ?siriusAnnotation ns1:has_InChIkey2D ?inChIKey2D1 .\\n    ?isdbAnnotation ns1:has_InChIkey2D ?inChIKey2D2 .\\n    FILTER (?inChIKey2D1 = ?inChIKey2D2)\\n}\",\n",
      "  \"file_path\": \"/var/folders/20/4kgcw5656h12ss_nj18mndwm0000gn/T/tmppow140s5.csv\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Let's create the dictionary as described and extract the content\n",
    "\n",
    "raw =  {\n",
    "    \"messages\": [\n",
    "      {\n",
    "        \"lc\": 1,\n",
    "        \"type\": \"constructor\",\n",
    "        \"id\": [\n",
    "          \"langchain\",\n",
    "          \"schema\",\n",
    "          \"messages\",\n",
    "          \"HumanMessage\"\n",
    "        ],\n",
    "        \"kwargs\": {\n",
    "          \"content\": \"How many features (pos ionization and neg ionization modes) have the same SIRIUS/CSI:FingerID and ISDB annotation by comparing the InCHIKey2D of the annotations?\"\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"lc\": 1,\n",
    "        \"type\": \"constructor\",\n",
    "        \"id\": [\n",
    "          \"langchain\",\n",
    "          \"schema\",\n",
    "          \"messages\",\n",
    "          \"HumanMessage\"\n",
    "        ],\n",
    "        \"kwargs\": {\n",
    "          \"content\": \"The number of features (in both positive and negative ionization modes) that have the same SIRIUS/CSI:FingerID and ISDB annotation, as determined by comparing the InCHIKey2D of the annotations, is 33,255.\\n\\n{\\n  \\\"question\\\": \\\"How many features (pos ionization and neg ionization modes) have the same SIRIUS/CSI:FingerID and ISDB annotation by comparing the InCHIKey2D of the annotations?\\\",\\n  \\\"generated_sparql_query\\\": \\\"PREFIX ns1: <https://enpkg.commons-lab.org/kg/>\\\\nSELECT (COUNT(DISTINCT ?feature) AS ?count)\\\\nWHERE {\\\\n    ?feature a ns1:LCMSFeature .\\\\n    ?feature ns1:has_sirius_annotation ?siriusAnnotation .\\\\n    ?feature ns1:has_isdb_annotation ?isdbAnnotation .\\\\n    ?siriusAnnotation ns1:has_InChIkey2D ?inChIKey2D1 .\\\\n    ?isdbAnnotation ns1:has_InChIkey2D ?inChIKey2D2 .\\\\n    FILTER (?inChIKey2D1 = ?inChIKey2D2)\\\\n}\\\",\\n  \\\"file_path\\\": \\\"/var/folders/20/4kgcw5656h12ss_nj18mndwm0000gn/T/tmppow140s5.csv\\\"\\n}\",\n",
    "          \"name\": \"Sparql_query_runner\"\n",
    "        }\n",
    "      }\n",
    "    ],\n",
    "    \"next\": \"FINISH\"\n",
    "  }\n",
    "\n",
    "\n",
    "# Then, extract and print the content from the specified location in the dictionary\n",
    "extracted_content = raw[\"messages\"][1][\"kwargs\"][\"content\"]\n",
    "print(extracted_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q1 = \"How many features (pos ionization and neg ionization modes) have the same SIRIUS/CSI:FingerID and ISDB annotation by comparing the InCHIKey of the annotations?\"\n",
    "q1_bis = \"How many features (pos ionization and neg ionization modes) have the same SIRIUS/CSI:FingerID and ISDB annotation by comparing the InCHIKey2D of the annotations?\"\n",
    "q2 = \"Which extracts have features (pos ionization mode) annotated as the class, aspidosperma-type alkaloids, by CANOPUS with a probability score above 0.5, ordered by the decreasing count of features as aspidosperma-type alkaloids? Group by extract.\"\n",
    "q3 = \"Among the structural annotations from the Tabernaemontana coffeoides (Apocynaceae) seeds extract taxon , which ones contain an aspidospermidine substructure?\"\n",
    "q4 = \"Among the SIRIUS structural annotations from the Tabernaemontana coffeoides (Apocynaceae) seeds extract, which ones are reported in the Tabernaemontana genus in Wikidata?\"\n",
    "q5 = \"Which compounds have annotations with chembl assay results indicating reported activity against T. cruzi by looking at the cosmic, zodiac and taxo scores?\"\n",
    "q5_bis = \"Which compounds have annotations with chembl assay results indicating reported activity against Trypanosoma cruzi by looking at the cosmic, zodiac and taxo scores?\"\n",
    "q6 = \"Filter the pos ionization mode features of the Melochia umbellata taxon annotated as [M+H]+ by SIRIUS to keep the ones for which a feature in neg ionization mode is detected with the same retention time (+/- 3 seconds) and a mass corresponding to the [M-H]- adduct (+/- 5ppm).\"\n",
    "q7 = \"For features from the Melochia umbellata taxon in pos ionization mode with SIRIUS annotations, get the ones for which a feature in neg ionization mode with the same retention time (+/- 3 seconds) has the same SIRIUS annotation by comparing the InCHIKey 2D. Return the features, retention times, and InChIKey2D\"\n",
    "q8 = \"Which features were annotated as 'Tetraketide meroterpenoids' by SIRIUS, and how many such features were found for each species and plant part?\"\n",
    "q9 = \"What are all distinct submitted taxons for the extracts in the knowledge graph?\"\n",
    "q10 = \"What are the taxons, lab process and label (if one exists) for each sample? Sort by sample and then lab process\"\n",
    "q11 = \"Count all the species per family in the collection\"\n",
    "\n",
    "q12 = \"Taxons can be found in enpkg:LabExtract. Find the best URI of the Taxon in the context of this question : \\n Among the structural annotations from the Tabernaemontana coffeoides (Apocynaceae) seeds extract taxon , which ones contain an aspidospermidine substructure, CCC12CCCN3C1C4(CC3)C(CC2)NC5=CC=CC=C45?\"\n",
    "q13 = \"Which compounds annotated in the active extract of Melochia umbellata have activity against Trypanosoma cruzi reported (in ChEMBL)?\"\n",
    "q14 = \"What are the variations in the concentration of key active compounds found in Tabernaemontana coffeoides seed extracts across different sample collections?\"\n",
    "q15 = \"Which compounds are detected most in Tabernaemontana genus?\"\n",
    "q16 = (\n",
    "    \"What are the most frequently detected compounds in the leaves of the Tabernaemontana genus? \"\n",
    "    \" over of features annotated as certain chemical classes vary across different Tabernaemontana genus extracts in the ENPKG, with a focus on features identified in positive ionization mode and annotated by CANOPUS with a probability score above 0.5?\"\n",
    ")\n",
    "q17 = \" For all the plant extracts plot the distribution of number of features per sample retention time vs mass to charge ratio\"\n",
    "q18 = \"What are the most frequently observed chemical compounds in Tabernaemontana genus? Provide a bar chart.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for s in app.stream(\n",
    "    {\"messages\": [HumanMessage(content=q7)]},\n",
    "    {\"recursion_limit\": 100},\n",
    "):\n",
    "    if \"__end__\" in s:\n",
    "        print(s)\n",
    "        print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for s in app.stream(\n",
    "    {\"messages\": [HumanMessage(content=q2)]},\n",
    "    {\"recursion_limit\": 100},\n",
    "):\n",
    "    if \"__end__\" in s:\n",
    "        print(s)\n",
    "        print(\"----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for s in app.stream(\n",
    "    {\"messages\": [HumanMessage(content=q2)]},\n",
    "    {\"recursion_limit\": 100},\n",
    "):\n",
    "    if \"__end__\" in s:\n",
    "        print(s)\n",
    "        print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for s in app.stream(\n",
    "    {\"messages\": [HumanMessage(content=q6)]},\n",
    "    {\"recursion_limit\": 100},\n",
    "):\n",
    "    if \"__end__\" in s:\n",
    "        print(s)\n",
    "        print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for s in app.stream(\n",
    "    {\"messages\": [HumanMessage(content=q3)]},\n",
    "    {\"recursion_limit\": 100},\n",
    "):\n",
    "    if \"__end__\" in s:\n",
    "        print(s)\n",
    "        print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_stream(app, q2):\n",
    "    results = []  # Initialize an empty list to store results\n",
    "    try:\n",
    "        # Iterate over the stream from app.stream()\n",
    "        for s in app.stream(\n",
    "            {\n",
    "                \"messages\": [\n",
    "                    HumanMessage(\n",
    "                        content=q2\n",
    "                    )  # Assuming q2 is the content of the message\n",
    "                ]\n",
    "            },\n",
    "            {\"recursion_limit\": 100},  # Additional options for the stream\n",
    "        ):\n",
    "            # Check if \"__end__\" is not in the stream output\n",
    "            if \"__end__\" not in s:\n",
    "                results.append(\n",
    "                    s\n",
    "                )  # Append the stream output to results list instead of printing\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "    return results  # Return the list of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_stream(question):\n",
    "    \"\"\"\n",
    "    Iterates over messages from app.stream(), printing each message until an \"__end__\" flag is encountered.\n",
    "\n",
    "    :param question: The question to be sent as part of the initial stream request.\n",
    "    \"\"\"\n",
    "    # Define the parameters for app.stream() as described\n",
    "    stream_params = {\n",
    "        \"messages\": [{\"content\": question}],\n",
    "    }\n",
    "    stream_options = {\"recursion_limit\": 100}\n",
    "\n",
    "    try:\n",
    "        for s in app.stream(stream_params, stream_options):\n",
    "            if \"__end__\" not in s:\n",
    "                print(s)\n",
    "                print(\"----\")\n",
    "            else:\n",
    "                break  # Exit the loop if \"__end__\" is encountered\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during streaming: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kgai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
