{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Evaluating Trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Single step evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "examples = [\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"i bought some tracks recently and i dont like them\"}], \"route\": \"refund_agent\"},\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"I was thinking of purchasing some Rolling Stones tunes, any recommendations?\"}], \"route\": \"question_answering_agent\"},\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"i want a refund on purchase 237\"}, {\"role\": \"assistant\", \"content\": \"I've refunded you a total of $1.98. How else can I help you today?\"}, {\"role\": \"user\", \"content\": \"did prince release any albums in 2000?\"}], \"route\": \"question_answering_agent\"},\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"i purchased a cover of Yesterday recently but can't remember who it was by, which versions of it do you have?\"}], \"route\": \"question_answering_agent\"},\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Can I get my money back? I bought an album from the store last week, but it was the wrong one.\"}], \"route\": \"refund_agent\"}\n",
    "]\n",
    "\n",
    "dataset_name = \"KGBot Evaluation: Single Step\"\n",
    "if not client.has_dataset(dataset_name=dataset_name):\n",
    "    dataset = client.create_dataset(dataset_name=dataset_name)\n",
    "    client.create_examples(\n",
    "        inputs = [{\"messages\": ex[\"messages\"]} for ex in examples],\n",
    "        outputs = [{\"route\": ex[\"route\"]} for ex in examples],\n",
    "        dataset_id=dataset.id\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define application logic to be evaluated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'kgbot (Python 3.13.0)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n kgbot ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Target function for running the relevant step\n",
    "async def run_intent_classifier(inputs: dict) -> dict:\n",
    "    # Note that we can access and run the intent_classifier node of our graph directly.\n",
    "    command = await graph.nodes['intent_classifier'].ainvoke(inputs)\n",
    "    return {\"route\": command.goto}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluator\n",
    "def correct(outputs: dict, reference_outputs: dict) -> bool:\n",
    "    \"\"\"Check if the agent chose the correct route.\"\"\"\n",
    "    return outputs[\"route\"] == reference_outputs[\"route\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run evaluation\n",
    "experiment_results = await client.aevaluate(\n",
    "    run_intent_classifier,\n",
    "    data=dataset_name,\n",
    "    evaluators=[correct],\n",
    "    experiment_prefix=\"sql-agent-gpt4o-intent-classifier\",\n",
    "    max_concurrency=4,\n",
    ")\n",
    "experiment_results.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Trajectory evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "client = Client()\n",
    "\n",
    "# Create a dataset\n",
    "examples = [\n",
    "    {\n",
    "        \"question\": \"How many songs do you have by James Brown\",\n",
    "        \"trajectory\": [\"intent_classifier\", \"question_answering_agent\", \"agent\", \"tools\", \"lookup_track\", \"agent\", \"compile_followup\"]\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"My name is Aaron Mitchell and I'd like a refund.\",\n",
    "        \"trajectory\": [\"intent_classifier\", \"refund_agent\", \"gather_info\", \"compile_followup\"],\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"My name is Aaron Mitchell and I'd like a refund on my Led Zeppelin purchases. My number is +1 (204) 452-6452\",\n",
    "        \"trajectory\": [\"intent_classifier\", \"refund_agent\", \"gather_info\", \"lookup\", \"compile_followup\"],\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Who recorded Wish You Were Here again? What other albums by them do you have?\",\n",
    "        \"trajectory\": [\"intent_classifier\", \"question_answering_agent\", \"agent\", \"tools\", \"lookup_track\", \"agent\", \"tools\", \"lookup_album\", \"agent\", \"compile_followup\"],\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"My name is Aaron Mitchell. My number is +1 (204) 452-6452 and I want a full refund for invoice id 237\",\n",
    "        \"trajectory\": [\"intent_classifier\", \"refund_agent\", \"gather_info\", \"refund\", \"compile_followup\"],\n",
    "    },\n",
    "]\n",
    "\n",
    "dataset_name = \"Chinook Customer Service Bot: Trajectory\"\n",
    "\n",
    "if not client.has_dataset(dataset_name=dataset_name):\n",
    "    dataset = client.create_dataset(dataset_name=dataset_name)\n",
    "    client.create_examples(\n",
    "        inputs=[{\"question\": ex[\"question\"]} for ex in examples],\n",
    "        outputs=[{\"trajectory\": ex[\"trajectory\"]} for ex in examples],\n",
    "        dataset_id=dataset.id\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define application logic to be evaluated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_graph(inputs: dict) -> dict:\n",
    "    \"\"\"Run graph and track the trajectory it takes along with the final response.\"\"\"\n",
    "    trajectory = []\n",
    "    # Set subgraph=True to stream events from subgraphs of the main graph: https://langchain-ai.github.io/langgraph/how-tos/streaming-subgraphs/\n",
    "    # Set stream_mode=\"debug\" to stream all possible events: https://langchain-ai.github.io/langgraph/concepts/streaming\n",
    "    async for chunk in graph.astream({\"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": inputs['question'],\n",
    "            }\n",
    "        ]}, subgraphs=True, stream_mode=\"debug\"):\n",
    "        # Event type for entering a node\n",
    "        if chunk[1]['type'] == 'task':\n",
    "            # Record the node name\n",
    "            trajectory.append(chunk[1]['payload']['name'])\n",
    "            # Given how we defined our dataset, we also need to track when specific tools are\n",
    "            # called by our question answering ReACT agent. These tool calls can be found\n",
    "            # when the ToolsNode (named \"tools\") is invoked by looking at the AIMessage.tool_calls\n",
    "            # of the latest input message.\n",
    "            if chunk[1]['payload']['name'] == 'tools' and chunk[1]['type'] == 'task':\n",
    "                for tc in chunk[1]['payload']['input']['messages'][-1].tool_calls:\n",
    "                    trajectory.append(tc['name'])\n",
    "    return {\"trajectory\": trajectory}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define evaluators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_extra_steps(outputs: dict, reference_outputs: dict) -> dict:\n",
    "    \"\"\"Evaluate the number of extra steps in the agent's output.\"\"\"\n",
    "    extra_steps = len(outputs['trajectory']) - len(reference_outputs['trajectory'])\n",
    "    return {\n",
    "        \"key\": \"extra_steps\",\n",
    "        \"score\": extra_steps,\n",
    "    }\n",
    "\n",
    "def evaluate_unmatched_steps(outputs: dict, reference_outputs: dict) -> dict:\n",
    "    # [\"step1\", \"step2\", \"step3\"]\n",
    "    # [\"step3\", \"step2\", \"step1\"]\n",
    "    \"\"\"Evaluate the number of unmatched steps in the agent's output.\"\"\"\n",
    "    i = j = 0\n",
    "    unmatched_steps = 0\n",
    "\n",
    "    while i < len(reference_outputs['trajectory']) and j < len(outputs['trajectory']):\n",
    "        if reference_outputs['trajectory'][i] == outputs['trajectory'][j]:\n",
    "            i += 1  # Match found, move to the next step in reference trajectory\n",
    "        else:\n",
    "            unmatched_steps += 1  # Step is not part of the reference trajectory\n",
    "        j += 1  # Always move to the next step in outputs trajectory\n",
    "\n",
    "    # Count remaining unmatched steps in outputs beyond the comparison loop\n",
    "    unmatched_steps += len(outputs['trajectory']) - j\n",
    "\n",
    "    return {\n",
    "        \"key\": \"unmatched_steps\",\n",
    "        \"score\": unmatched_steps,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_results = await client.aevaluate(\n",
    "    run_graph,\n",
    "    data=dataset_name,\n",
    "    evaluators=[evaluate_extra_steps, evaluate_unmatched_steps],\n",
    "    experiment_prefix=\"sql-agent-gpt4o-trajectory\",\n",
    "    num_repetitions=1,\n",
    "    max_concurrency=4,\n",
    ")\n",
    "experiment_results.to_pandas()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kgbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
